commentOrDocument,modifyDate,docketId,commentOnDocumentId,id,organization,firstName,lastName,title,comment,attachments,link,GPT_summary
document,2024-10-14T01:00:58Z,BIS-2024-0047,,BIS-2024-0047-0001,,,,Reporting Requirements for the Development of Advanced Artificial Intelligence Models and Computing Clusters,,"[('Reporting Requirements for the Development of Advanced Artificial Intelligence Models and Computing Clusters', 'https://downloads.regulations.gov/BIS-2024-0047-0001/content.pdf')]",https://api.regulations.gov/v4/documents/BIS-2024-0047-0001,
comment,2024-10-22T19:46:11Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0003,Americans for Prosperity Foundation,,,Public Comment 2. Other. Americans for Prosperity,See attached file(s),"[('2024.10.07 AFPF Regulatory Comment to BIS on DPA AI Reporting Requirements', 'https://downloads.regulations.gov/BIS-2024-0047-0003/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0003,"Americans for Prosperity Foundation (AFP Foundation) opposes the Bureau of Industry and Security's proposed rulemaking on reporting requirements for AI models, arguing that it stifles innovation, misuses emergency powers, and lacks clear congressional authorization. They criticize the administration's overreach and suggest that AI regulation should follow traditional protocols, not emergency measures. They highlight concerns about data security and the potential negative impact on AI development. AFP Foundation calls for the abandonment of the proposed reporting requirements and recommends Congress take a more active role in overseeing AI regulation."
comment,2024-10-22T19:46:30Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0036,Mozilla,,,Public Comment 31. U.S. Business. Mozilla,See attached file(s),"[('BIS_Reporting_Requirements_Response_Submission_2024-10-11', 'https://downloads.regulations.gov/BIS-2024-0047-0036/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0036,"Mozilla emphasizes the importance of openness in AI for safety, transparency, and innovation. They suggest that regulations should consider the unique attributes of the open-source AI ecosystem to avoid hindering smaller entities. Mozilla advocates for clear definitions, regular updates, and information sharing on cybersecurity measures for AI models. They highlight the economic and national security benefits of open source AI, urging regulators to prioritize the needs of the open-source community in drafting and implementing rules."
comment,2024-10-22T19:46:12Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0004,IBM,,,Public Comment 3. U.S. Business. IBM,See attached file(s),"[('RFC on BIS AI Rulemaking - Final', 'https://downloads.regulations.gov/BIS-2024-0047-0004/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0004,"IBM responds to the Bureau of Industry and Security's proposed rule on reporting requirements for advanced AI systems, in line with Executive Order 14110. They commend BIS for the RFC but suggest clarifying the scope of reportable information and providing more time for responses. IBM urges consistency with the EO to prevent hindering the AI marketplace. Christina Montgomery, Chief Privacy and Trust Officer at IBM, emphasizes the importance of aligning with the EO's intent and allowing sufficient time for organizations to respond effectively."
comment,2024-10-22T19:46:14Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0008,,,Madkour,"Public Comment 7. Individual. Anthony Barrett, Nada Madkour, Evan Murphy, Jessica Newman","To the Bureau of Industry and Security,<br/><br/>Thank you for the opportunity to submit comments in response to the proposed rule Establishment of Reporting Requirements for the Development of Advanced Artificial Intelligence Models and Computing Clusters (89 FR 73612) (RIN 0694-AJ55). We offer the following submission for your consideration. My colleagues and I are researchers affiliated with UC Berkeley, with expertise in AI research and development, safety, security, policy, and ethics (while we collaborated in drafting this comment, it is submitted in a personal capacity). <br/><br/>We agree with the text in the proposed rule that &ldquo;the U.S. Government needs information about how many U.S. companies are developing, have plans to develop, or have the computing hardware necessary to develop dual-use foundation models, as well as information about the characteristics of dual-use foundation models under development,&rdquo; and that &ldquo;the integration of AI models into the defense industrial base also requires the U.S. Government to take actions as needed to ensure that dual-use foundation models operate in a safe and reliable manner.&rdquo; Our research underscores that &ldquo;these models may operate in unpredictable or unreliable ways, potentially resulting in dangerous accidents,&rdquo; and we strongly agree that the U.S. Government needs information about how companies have tested the safety and reliability of their models, including red-teaming results and risk mitigation efforts. (See, e.g., our report &ldquo;Benchmark Early and Red Team Often: A Framework for Assessing and Managing Dual-Use Hazards of AI Foundation Models&rdquo;, Barrett et al. 2024.) Furthermore, we strongly agree that the U.S. Government must minimize the vulnerability of dual-use foundation models to cyberattacks, which will require information about companies&rsquo; cybersecurity measures, resources, and practices.<br/><br/>One key aspect of the proposed rule is that it provides some basic hard-law requirements for reasonable risk-management steps by developers of dual-use foundation models. Several leading developers currently carry out important risk management steps on a voluntary basis, and soft-law voluntary AI risk management standards serve a valuable role in AI governance. However, reasonable hard-law requirements and enforcement provide additional, worthwhile incentives for developers of dual-use foundation models to take important risk-management steps that can affect public safety, such as to help prevent bio- or cyber-attacks substantially assisted by malicious misuse of dual-use foundation models. (See, e.g., our &ldquo;Policy Brief on AI Risk Management Standards for General-Purpose AI Systems (GPAIS) and Foundation Models&rdquo;, Barrett, Newman et al. 2023). <br/><br/>We support the requirements and the outlined approach defined in the Reporting Requirements, including quarterly reporting from companies developing dual-use foundation models or large-scale computing clusters. The quarterly notification schedule is appropriate because it allows for extremely minimal reporting in instances where companies have no notable changes. Given the pace of change in the field, this frequency is warranted and important for timely information gathering. <br/><br/>We also encourage consideration of refinements to the collection threshold for dual-use foundation models. Close monitoring of new models, and trends in hardware and algorithmic efficiency, may indicate that substantial dual-use capabilities could be present in models with training runs utilizing lower or higher amounts of computational operations than the currently proposed thresholds. <br/><br/>Our best,<br/><br/>Anthony Barrett, Ph.D., PMP<br/>Visiting Scholar<br/>AI Security Initiative, Center for Long-Term Cybersecurity, UC Berkeley<br/><br/>Nada Madkour, Ph.D.<br/>Non-Resident Research Fellow<br/>AI Security Initiative, Center for Long-Term Cybersecurity, UC Berkeley<br/><br/>Evan R. Murphy<br/>Non-Resident Research Fellow<br/>AI Security Initiative, Center for Long-Term Cybersecurity, UC Berkeley<br/><br/>Jessica Newman<br/>Director<br/>AI Security Initiative, Center for Long-Term Cybersecurity, UC Berkeley<br/>Co-Director<br/>AI Policy Hub, UC Berkeley<br/><br/>References <br/>Anthony M. Barrett, Krystal Jackson, Evan R. Murphy, Nada Madkour, Jessica Newman (2024). Benchmark Early and Red Team Often: A Framework for Assessing and Managing Dual-Use Hazards of AI Foundation Models. arXiv preprint, https://arxiv.org/abs/2405.10986<br/><br/>Anthony M. Barrett, Jessica Newman, and Brandie Nonnecke (2023) Policy Brief on AI Risk Management Standards for General-Purpose AI Systems (GPAIS) and Foundation Models. UC Berkeley Center for Long-Term Cybersecurity, https://cltc.berkeley.edu/publication/policy-brief-on-ai-risk-management-standards-for-general-purpose-ai-systems-gpais-and-foundation-models/ <br/><br/>Attached is a PDF copy of our comment including links to the cited resources. ","[('Comment on Development of Advanced Artificial Intelligence Models and Computing Clusters (RIN 0694-AJ55) NMadkour', 'https://downloads.regulations.gov/BIS-2024-0047-0008/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0008,
comment,2024-10-22T19:46:12Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0005,Center for AI Policy,,,Public Comment 4. Other. Center for AI Policy,See attached file(s).,"[('RFC _ Reporting Requirements', 'https://downloads.regulations.gov/BIS-2024-0047-0005/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0005,"The Center for AI Policy (CAIP) commends the Bureau of Industry & Security (BIS) on the proposed rule for reporting requirements on Advanced Artificial Intelligence Models and Computing Clusters. CAIP supports the quarterly notification schedule, suggests using encrypted file sharing for data collection, and recommends regular review of computing thresholds. They also advocate for clear information requirements, minimal compliance costs, and emphasize the importance of AI safety for critical infrastructure and national defense. CAIP supports the proposed rule with suggested amendments to enhance visibility and safety evaluations."
comment,2024-10-22T19:46:10Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0002,,,Renner,Public Comment 1. Individual. Erik Renner. 09/16/24,See attached file(s),"[('Commnet on Reporting Requirements for AI', 'https://downloads.regulations.gov/BIS-2024-0047-0002/attachment_1.docx')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0002,
comment,2024-10-22T19:46:18Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0016,,,Anonymous,Public Comment 13. Individual. Anonymous (2)- Part 3 of 7,"PUBLIC COMMENT CONTINUED<br/>RIN 0694-AJ55 <br/>October 11, 2024<br/><br/>III. QUARTERLY REPORTING WOULD IMPOSE EXTREME BURDENS THAT ARE NOT SUPPORTED BY THE STATED GOALS OF THE PROPOSED RULE.<br/><br/>The proposed rule would require companies that are (or will be) engaged in covered activities to submit reports on a quarterly basis. BIS states that these reporting requirements &ldquo;are expected to apply to only a small number of entities&rdquo; and estimates the number of respondents that exceed the reporting thresholds for models and computing clusters is between zero and 15 companies. At the same time BIS provides &ldquo;an estimated burden of 5,000 hours per year aggregated across all new respondents.&rdquo; This signals an extremely burdensome compliance obligation per respondent that would effectively mean that respondents are in a constant state of preparing reports, submitting reports, and responding to questions from BIS regarding reports.<br/><br/>Although BIS proposes to allow additions, updates or changes to the information provided on previous surveys submitted by a respondent, this does not alleviate the burden on respondents because they must still expend significant employee time and resources to determine whether such updates are required while at the same time evaluating their ongoing reporting requirements and respond to BIS questions. This is especially true given the detailed and lengthy nature of information normally required by BIS in industry surveys.<br/><br/>The proposed rule does not explain why quarterly reporting, or even annual reporting, is necessary instead of one-time reports. As noted above, BIS states that it needs quarterly reports for information &ldquo;that will allow the U.S. Government to determine whether action is necessary to stimulate development of dual-use foundation models or to support the development of specific types of models.&rdquo; However, this is similar to the rationales provided for other industrial base surveys, including those in the U.S. microelectronics and space industries as well as BIS&rsquo;s previous survey of the U.S. AI industry which addressed areas of national security concern, but only involved a one-time reporting requirement.","[('image', 'https://downloads.regulations.gov/BIS-2024-0047-0016/attachment_1.png')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0016,
comment,2024-10-22T19:46:19Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0018,,,Anonymous,Public Comment 13. Individual. Anonymous (2)- Part 5 of 7,"PUBLIC COMMENT CONTINUED<br/>RIN 0694-AJ55 <br/>October 11, 2024<br/><br/>V. BIS SHOULD ELIMINATE AND/OR CLARIFY EMPLOYEE REPORTING OBLIGATIONS.<br/><br/>AI TRAINING RUN REPORTING<br/><br/>The AI training run reporting requirements are broader than the mandate in EO 14110 and should be revised to be consistent with that mandate. Section 4.2(a)(i) of EO 14110, directs the Secretary of Commerce to require &ldquo;Companies developing or demonstrating an intent to develop potential dual-use foundation models to provide the Federal Government, on an ongoing basis, with information, reports, or records&hellip;&rdquo;  The AI model training run reporting requirement at section 702.7(a)(1)(i), however, extends to &ldquo;covered U.S. persons,&rdquo; which per proposed section 701.7(c) would be defined to include any individual U.S. citizen, lawful permanent resident, or any person (individual) located in the United States.<br/><br/>Insofar as proposed section 702.7(a)(i) would require employees to report AI model training runs by their company, it is inconsistent with section 4.2(a)(i) of EO 14110, which directs the Secretary of Commerce to require &ldquo;Companies developing or demonstrating an intent to develop potential dual-use foundation models to provide the Federal Government, on an ongoing basis, with information, reports, or records&hellip;&rdquo;  In addition to going beyond the mandate of EO 14110, applying the reporting requirement to individual employees appears to be beyond the stated policy intent, which is focused on the U.S. industrial base.<br/><br/>BIS should therefore revise proposed section 702.7(a)(1)(i) to reflect that the AI model training reporting requirement is triggered and reportable by the U.S. organization, company, or corporation engaged in the applicable activity [recommended edits in CAPS]:<br/><br/>(a) Reporting Requirements<br/>(1) As set forth below, U.S. Covered persons or U.S. organizations, companies, and corporations are required to submit a notification to the Department by emailing ai_reporting@bis.doc.gov on a quarterly basis as defined in paragraph (a)(2) of this section if the relevant party engages in, or plans, within six months, to engage in &lsquo;applicable activities,&rsquo; defined as follows:<br/>(i) US ORGANIZATIONS, COMPANIES, AND CORPORATIONS [c]onducting any AI model training run using more than 10^26 computational operations (e.g., integer or floating-point operations);<br/><br/>At a minimum, if BIS is unable to make the revision above, BIS should clarify that reports on AI model training are only required for U.S. entities, and not for U.S. person employees of U.S. or non-U.S. entities, even if they are involved in AI model training in the course of their employment.<br/><br/>COMPUTER CLUSTER REPORTING<br/><br/>Proposed section 702.7(a)(ii) requires reporting by both companies and individuals who acquire, develop, or come into possession of a computing cluster exceeding specified thresholds.  While consistent with the EO 14110 mandate at Section 4.2(ii) which instructs the Secretary of Commerce to require &ldquo;Companies, individuals, or other organizations or entities that acquire, develop, or possess a potential large-scale computing cluster to report any such acquisition, development, or possession, including the existence and location of these clusters and the amount of total computing power available in each cluster,&rdquo; the proposed rule is broader than BIS&rsquo;s statement in the preamble where it describes that it is &ldquo;exercising its DPA authority, . . . to collect information from U.S. companies that are developing, have plans to develop, or have the computing hardware necessary to develop dual-use foundation models.&rdquo;<br/><br/>To the extent that BIS intends to require computing cluster reporting by individual U.S. persons, BIS should clarify that the requirement does not apply to individual employees of U.S. companies engaged in such activities and should provide guidance on scope of the individual reporting requirements. Such guidance should, at a minimum, confirm that:<br/>&bull;  An employee is not required to submit a report when his/her company has already submitted a report on the applicable activity to BIS.<br/>&bull;  An individual only has a reporting obligation when they are acting on their own behalf.<br/>&bull;  An employee executing their non-discretionary duties (e.g., processing a procurement order; installing or servicing hardware) is not engaged in the acquisition, development, or gaining possession of a computing cluster as contemplated in proposed section 702.7(a)(ii).<br/>&bull;  A U.S. person&rsquo;s mere use of a computing cluster located outside the United States that exceeds a stated threshold does not constitute the acquisition, development, or possession of a computing cluster.","[('image', 'https://downloads.regulations.gov/BIS-2024-0047-0018/attachment_1.png')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0018,
comment,2024-10-22T19:46:14Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0009,,,Belmona,Public Comment 8. Individual. Amanda Belmona,"Dear Thea D. Rozman Kendler, <br/><br/>I support the proposed rule establishing reporting requirements for developing advanced artificial intelligence (AI) models and computing clusters. As AI continues to play an increasingly significant role in various sectors, including healthcare, finance, and national security, it is crucial to implement oversight mechanisms that ensure responsible development and deployment of these technologies. This proposed rule will provide necessary transparency, helping mitigate AI risks, such as bias, ethical concerns, and potential misuse.<br/>The establishment of reporting requirements will not only enhance accountability among developers and contribute to a more comprehensive understanding of AI&rsquo;s societal impacts. We can facilitate better collaboration between government agencies, private industry, and academic institutions by requiring developers to disclose information about their AI models and computing resources. Research indicates that transparent AI practices can increase public trust and acceptance of AI technologies (Nabavi &amp; Browne, 2023). Furthermore, studies have shown that organizations that adopt transparent AI practices are more likely to foster inclusive innovation, ensuring that diverse perspectives are considered in the development process (West et al., 2019). Additionally, implementing these reporting requirements aligns with global best practices for AI governance. The OECD&rsquo;s &ldquo;Principles on Artificial Intelligence&rdquo; emphasize the importance of transparency and accountability in AI systems, which can help build a solid framework for ethical AI development (OECD, 2024, pg 6). By adopting similar reporting standards, the U.S. can position itself as a leader in ethical AI practices and ensure that innovations benefit society while addressing potential risks.<br/>While some argue that these reporting requirements could stifle innovation or impose unnecessary burdens on developers, it is essential to recognize that transparency and responsible development do not have to come at the expense of innovation. Instead, these requirements can be a foundation for fostering ethical practices, leading to more robust and reliable AI solutions. We can address societal concerns by prioritizing responsible AI development while encouraging progress in this transformative field. I strongly support the proposed reporting requirements for advanced AI models and computing clusters. Implementing these measures will enhance accountability, promote ethical development, and help ensure that AI technologies benefit society. <br/><br/>Sincerely,<br/>Amanda Belmona<br/><br/>References:<br/>Nabavi, E., &amp; Browne, C. (2023). Leverage zones in Responsible AI: towards a systems thinking conceptualization. Humanities and Social Sciences Communications, 10(1). https://doi.org/10.1057/s41599-023-01579-0<br/>West, S.M., Whittaker, M. &amp; Crawford, K. (2019). Discriminating Systems: Gender, Race, and Power in AI. AI Now Institute. https://ainowinstitute.org/publication/discriminating-systems-gender-race-and-power-in-ai-2<br/>OECD (2024). OECD updates AI Principles to stay abreast of rapid technological developments. https://www.oecd.org/en/about/news/press-releases/2024/05/oecd-updates-ai-principles-to-stay-abreast-of-rapid-technological-developments.html<br/>",[],https://api.regulations.gov/v4/comments/BIS-2024-0047-0009,
comment,2024-10-22T19:46:32Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0040,,,Anonymous,Public Comment 35. Individual. Anonymous,"This rule applies to companies who are working with Dual Use foundation models. Dual use foundation models are trained wide range of data with tens of billions of parameters. These models can significantly impact every sphere of human life. The executive order &ldquo;Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence&rdquo; (E.O. 14110) set forth the rules by which the burea of industry and security will monitor that AI models are being developed in a responsible way. This is definitely a double edged sword. At one point, we would want companies to have freedom to innovate but on the other hand we can see the potential negative consequences of large AI models in the wrong hands in terms of large scale cyberwarfare and crimes. As with most physical technologies that require patents and approvals from FDA etc, AI based models should also continue to have scrutiny especially as it relates to defense. I agree with the proposed rule under the executive order EO 14110.",[],https://api.regulations.gov/v4/comments/BIS-2024-0047-0040,
comment,2024-10-22T19:46:13Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0007,WhoPoo App,,,Public Comment 6. US Business. WhoPoo App,"Biometrics don&#39;t work. Refer to the latest USCCR report on this, about facial recognition. The official recommendation is to NOT use biometrics because they have very high error rates among POC and the elderly, and there are currently no biometric data use policies posted on the DHS website to deter privacy concerns. See https://www.usccr.gov/reports/2024/civil-rights-implications-federal-use-facial-recognition-technology With respect to FRT accuracy and bias, the National Institute of Standards and Technology (NIST) <br/>testing is voluntary and represents laboratory&mdash;not real-world&mdash;results. Thus, NIST cannot say that <br/>its evaluated programs are accurately representative of the performance of all FRT deployed <br/>throughout the country. Algorithmic accuracy rates can vary widely among developers, but even with <br/>the highest-performing algorithms, tests have shown there are likely to be false positives for certain <br/>demographic groups, specifically Black people (particularly Black women), people of East Asian <br/>descent, women, and older adults. A promising FRT testing model does exist: DHS, through its <br/>Science and Technology Directorate, funds FRT research, testing, and evaluation at MdTF, which <br/>specializes in &ldquo;scenario testing&rdquo; of the entire FRT system as it is intended to be deployed. DHS is <br/>the only agency known to be testing FRT in this way.   Any agency using FRT should have a publicly available use policy. If agencies do use FRT, they <br/>should audit their use to ensure it complies with government policy. FRT vendors providing the <br/>federal government with solutions should provide users with ongoing training, technical support, <br/>and software updates to ensure their systems can maintain high accuracy across demographic groups <br/>in real-world deployment contexts. Furthermore, agencies should ensure their CAIOs work in close <br/>coordination with existing responsible officials and organizations within their organizations, <br/>including Civil Rights and General Counsel offices, to advise and update agency FRT guidance, <br/>implementation, and oversight. <br/>Federal grantees using FRT should provide verified results with respect to accuracy and performance <br/>across demographics from NIST&rsquo;s FRT Evaluation or similar government-validated third-party test.<br/><br/>",[],https://api.regulations.gov/v4/comments/BIS-2024-0047-0007,
comment,2024-10-22T19:46:15Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0010,,,Anonymous,Public Comment 9. Individual. Annoymous,"Hi,<br/><br/>AI certainly has a perception of being one day like Skynet from Terminator 2. And my understanding is that many of these AI projects, must have some funding provided from the Department of Defense or other government entities. It would be interesting to learn for the public, as to how is machine learning for the AI, going to be used in matters of national defense. And will AI be just used as an aid or giving instructions of its own as well. I believe that the public should be also made aware of how AI is being used if they are receiving government funding. ",[],https://api.regulations.gov/v4/comments/BIS-2024-0047-0010,
comment,2024-10-22T19:46:22Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0022,Alliance for Trust in AI,,,Public Comment 15. Other. Alliance for Trust in AI,Please find attached comments from the Alliance for Trust in AI. Thank you for the opportunity to provide input.,"[('ATAI BIS NPRM Significant Malicious Cyber-Enabled Activities', 'https://downloads.regulations.gov/BIS-2024-0047-0022/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0022,"The Alliance for Trust in AI (ATAI) submitted comments to the Bureau of Industry and Security regarding the proposed rule on reporting requirements for the development of advanced AI models and computing clusters. ATAI seeks effective policy and clear codes of practice for AI, emphasizing the need for clarifying the rule's scope, re-evaluating reporting frequency, and setting appropriate thresholds for reporting based on risk types rather than just model size. They recommend exploring alternative approaches to numerical thresholds to reduce reporting burdens, especially for smaller companies. ATAI believes context is crucial in assessing risk associated with AI models and suggests annual reporting requirements instead of quarterly ones to prevent disincentives for innovation and development."
comment,2024-10-22T19:46:20Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0020,,,Anonymous,Public Comment 13. Individual. Anonymous (2)- Part 7 of 7,"PUBLIC COMMENT CONTINUED<br/>RIN 0694-AJ55 <br/>October 11, 2024<br/><br/>VII. BIS SHOULD CLARIFY HOW TO CALCULATE APPLICABLE THRESHOLDS.<br/><br/>BIS should also clarify how to calculate the thresholds contained within the NPRM, i.e., &ldquo;Conducting any AI model training run using more than 10^26 computational operations (e.g., integer or floating-point operations); or Acquiring, developing, or coming into possession of a computing cluster that has a set of machines transitively connected by data center networking of greater than 300 Gbit/s and having a theoretical maximum greater than 10^20 computational operations (e.g., integer or floating-point operations) per second (OP/s) for AI training, without sparsity.&rdquo;<br/><br/>In particular, BIS should define the terms &ldquo;computing cluster,&rdquo; &ldquo;transitively connected,&rdquo; and &ldquo;data center networking.&rdquo; The following definitions of these terms would be consistent with industry usage:<br/>&bull;  &ldquo;Computing cluster&rdquo; means a set of machines for which the connection between any two machines (including transitive connections) are at least 300 Gbit/s. If two machines are connected through links that are not able to operate at 300 Gbit/s, they should not be considered part of the same cluster.<br/>&bull;  &ldquo;Transitively connected&rdquo; means that two machines are connected through one or more intermediary machines, where the network bandwidth of the transitively connected machines is the bandwidth of communications between the machines based on the most direct path between the machines. For example, if machines A and B are directly connected by a 300 Gbit/s second connection, and B and C are directly connected by a 150 Gbit/s connection, then A and C are connected transitively with a 150 Gbit/s connection (as that is the maximum potential communication between the machines).<br/>&bull;  &ldquo;Data center networking&rdquo; should mean routers, switches, and other hardware components that enable connectivity needed to process data and run applications within a single data center. The term does not include modern cloud networks that incorporate virtualization to support data workloads and applications.<br/><br/>In addition, BIS should clarify the following:<br/>&bull;  What would constitute a single training run?<br/>-  If training takes place on a model, and at a later date (potentially much later) a decision is made to further fine-tune or otherwise enhance the model, is this second set of activity a new &ldquo;training run&rdquo; or a continuation of the first &ldquo;training run&rdquo;?<br/>-  Does the length of time between the two activities matter to this determination? <br/>-  Does it make a difference if the model was considered finished after the first run <br/>and put into productive use, before the later decision to further enhance it? <br/>-  Would it matter if the initial training was conducted by someone unrelated to the reporting person (e.g., an open source model) before the later fine-tuning or enhancement? <br/>&bull;  How is a training run that occurs across multiple quarters to be reported? For example, if the number of computational operations in each quarter is below the reporting threshold, but the total across all quarters is above the threshold, for which quarter (if any) would the run be reported?<br/>&bull;  What constitutes a single AI model for tallying up the resources used for training a model? For example, in cases where multiple distinct models are trained for different purposes, but in practice may be used in a coordinated way, are they to be considered a single AI model (with all of their individual training runs being consolidated for reporting as a single run)? Does it matter whether individual models are commonly used separately and not in coordination with other models?<br/>&bull;  For computing clusters:<br/>-  Are the theoretical maximum performance values based on peak performance or sustained performance?<br/>-  Is the 300 Gbit/s networking threshold a measure of per-link speed, or some other measure? If different parts of a cluster have links of different bandwidth, how does that affect the calculation?<br/>-  If two parts of a cluster are not connected transitively by links of at least 300 Gbit/s, are they considered separate clusters for purposes of the rule?<br/>-  What types of sparsity are excluded from the calculations, and how should the performance calculation take this into account?<br/>&bull;  What constitutes &ldquo;possession&rdquo; of a large-scale computing cluster, and how does shared usage of a cluster by unrelated parties affect the determination of who is in possession of it?<br/><br/>Thank you for your consideration.","[('image', 'https://downloads.regulations.gov/BIS-2024-0047-0020/attachment_1.png')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0020,
comment,2024-10-22T19:46:25Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0028,Centre for the Governance of AI (GovAI),,,Public Comment 21. Center for AI Governance,See attached file(s),"[('Submitted_GovAI_Response to BIS RFC on the Establishment of Reporting Requirements for the Development of Advanced Artificial Intelligence Models and Computing Clusters', 'https://downloads.regulations.gov/BIS-2024-0047-0028/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0028,The submission from the Centre for the Governance of AI (GovAI) commends the Bureau of Industry and Security (BIS) for proposing reporting requirements for advanced AI models and computing clusters. They support thresholds for reporting on dual-use foundation model development and recommend a formal annual review process to reassess reporting thresholds and ensure effectiveness as AI evolves. They propose specific recommendations for reporting thresholds based on training compute and emphasize the need for flexibility in the regulatory framework to adapt to technological advancements.
comment,2024-10-22T19:46:35Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0044,ACT | The App Association,,,Public Comment 39. Industry Association. ACT- The App Association,See attached for comments of ACT | The App Association,"[('ACT Comments re BIS Advanced AI Reporting Proposed Rule (11 Oct 2024) (w appendicies)', 'https://downloads.regulations.gov/BIS-2024-0047-0044/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0044,"The App Association submitted comments to the U.S. Department of Commerce on the proposed rule requiring reporting on the development of advanced dual-use AI models. They emphasize the importance of AI in various industries and urge for policies that align with safety, efficacy, and equity standards. They recommend scalable risk-based harm mitigation, alignment with NIST and AISI efforts, clear responsibilities for small businesses, and support for international harmonization. The association also provides policy recommendations and a framework outlining roles and interdependencies in the AI value chain. They stress the need for careful consideration of risks, responsibilities, and ethical use in AI development and deployment."
comment,2024-10-22T19:46:21Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0021,"Hugging Face, Inc.",,,Public Comment 14. U.S. Business. Hugging Face,The proposed rule regarding Establishment of Reporting Requirements for the Development of Advanced Artificial Intelligence Models and Computing Clusters covers important aspects of reporting; it sets clear goals of who should be required to report and excludes small actors who might not have the resources to fulfill regular reporting requirements. It further recognizes the changing nature of AI technology by ensuring that requirements and thresholds can be updated. <br/>We offer recommendations to strengthen the reporting requirements based on our experience with model documentation and work on social impact evaluations in the attached document.,"[('Hugging_Face_Comments__BIS-2024-0047__RIN 0694-AJ55', 'https://downloads.regulations.gov/BIS-2024-0047-0021/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0021,"Hugging Face provides feedback on the proposed rule regarding reporting requirements for the development of advanced AI models and computing clusters. They emphasize the importance of inclusive reporting requirements and recommend strengthening them based on their experience with model documentation and social impact evaluations. Hugging Face highlights the value of open science and collaboration in AI research, advocating for regulatory requirements compatible with these principles. They propose a two-stage reporting scheme and stress the need for comprehensive risk management frameworks. Additionally, they suggest refining the definitions of AI red-teaming and AI models and systems to enhance regulatory efforts and risk assessment."
comment,2024-10-22T19:46:23Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0023,Palisade Research,,,Public Comment 16. Other. Palisade Research,Please see our comment in the attached file.,"[('BIS Comment_Palisade Research', 'https://downloads.regulations.gov/BIS-2024-0047-0023/attachment_1.pdf'), ('BIS Comment_Supplement_Wasil et al', 'https://downloads.regulations.gov/BIS-2024-0047-0023/attachment_2.pdf'), ('Supplement_Wasil et al_Semi-structured Interviews', 'https://downloads.regulations.gov/BIS-2024-0047-0023/attachment_3.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0023,"Palisade Research, an organization focusing on AI security risks, suggests improvements to the reporting requirements for entities developing dual-use foundation models. They propose mechanisms for insiders to report concerns anonymously, regular interviews with employees, capability forecasts, a summary form for non-technical audiences, and amended notification conditions for sudden advancements. Their recommendations aim to enhance the effectiveness and robustness of the reporting process to support national defense interests. They provide draft language and rationale for each suggestion, emphasizing the need for timely and accurate information sharing."
comment,2024-10-22T19:46:35Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0045,ControlAI,,,Public Comment 40. Other. Control AI,See attached file(s),"[('FINAL comments on BIS-2024-0047 Establishment of Reporting Requirements', 'https://downloads.regulations.gov/BIS-2024-0047-0045/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0045,"ControlAI, a non-profit organization focused on global security risks from advanced AI systems, supports the Department of Commerce's Proposed Rule BIS-2024-0047. They suggest strengthening the rule by expanding AI red teaming efforts, including dangerous behaviors in reporting requirements, enhancing cybersecurity measures, adjusting reporting cadence, setting thresholds for FLOPs, and proposing an analytic approach to assess national security risks posed by AI companies. They aim to provide valuable input to protect the American people and offer ongoing support and expertise."
comment,2024-10-22T19:46:34Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0042,Intel Corporation,,,Public Comment 37. U.S. Business. Intel,See attached file(s),"[('Intel_comments_Reporting_Requirements_final', 'https://downloads.regulations.gov/BIS-2024-0047-0042/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0042,"Intel appreciates the chance to comment on the BIS Proposed Rule on Reporting Requirements for Advanced Artificial Intelligence Models and Computing Clusters. They express concerns about unclear definitions potentially expanding reporting obligations. Intel suggests revising the definition of ""training run"" to exclude optimization techniques. They also seek clarity on terms like ""transitively connected"" and ""theoretical maximum"" for computing clusters. Intel recommends BIS to update technical parameters promptly to keep pace with AI innovation. Intel looks forward to further engagement with the Department of Commerce on AI technology development and deployment."
comment,2024-10-22T19:46:16Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0012,Institute for AI Policy and Strategy,,,Public Comment 11. Other. Institute for AI Strategy and Policy,See attached file(s),"[('IAPS Response to BIS RFC on Establishment of Reporting Requirements for Development of Advanced AI Models and Computing Clusters', 'https://downloads.regulations.gov/BIS-2024-0047-0012/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0012,"The response from the Institute for AI Policy and Strategy (IAPS) to the BIS proposal focuses on expanding stakeholder involvement in reporting requirements for advanced AI models. They recommend voluntary reporting pathways for individual staff and third parties, amending notification schedules, convening a multistakeholder process for refining reporting standards, and enabling the sharing of safety-critical information. They suggest establishing clear guidance for information sharing and propose BIS serve as an information clearinghouse for safety and security-critical information related to AI systems. Additionally, they outline potential responses to dual-use capabilities by various stakeholders."
comment,2024-10-22T19:46:18Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0015,,,Anonymous,Public Comment 13. Individual. Anonymous (2)- Part 2 of 7,"PUBLIC COMMENT CONTINUED<br/>RIN 0694-AJ55 <br/>October 11, 2024<br/><br/>II. THE AI MODEL TRAINING RUN REPORTING REQUIREMENT EXCEEDS THE SCOPE OF EXECUTIVE ORDER 14110 BECAUSE IT DOES NOT FOCUS ON DUAL-USE FOUNDATION MODELS AND IS TRIGGERED WHEN A COVERED U.S. PERSON MERELY CONDUCTS ANY AI MODEL TRAINING USING MORE THAN A STATED COMPUTATIONAL CAPACITY.<br/><br/>Section 4.2(a)(i) of EO 14110, &ldquo;directs the Secretary of Commerce to require companies developing, or demonstrating an intent to develop, potential dual-use foundation AI models to provide certain information to the Federal Government on an ongoing basis.&rdquo; As defined under EO 14110, a &ldquo;dual-use foundation model&rdquo; is a model that &ldquo;could be easily modified to exhibit, high levels of performance at tasks that pose a serious risk to security, national economic security, national public health or safety, or any combination of those matters.&rdquo;<br/><br/>Consistent with EO 14110, the preamble to the proposed rule provides: &ldquo;The reporting requirements proposed in this regulation are intended to apply to dual-use foundation models that meet technical conditions issued by the Department.&rdquo; BIS further states: &ldquo;the U.S. Government needs information about how many U.S. companies are developing, have plans to develop, or have the computing hardware necessary to develop dual-use foundation models, as well as information about the characteristics of dual-use foundation models under development.&rdquo;<br/><br/>Despite the focus on dual-use foundation models in EO 14110 and the preamble to the proposed rule, the AI model run reporting requirement at proposed section 702.7(a)(1)(i) are triggered when a &ldquo;covered U.S. person engages in, or plans, within six months, to engage in... conducting any AI model training run using more than 10^26 computational operations (e.g., integer or floating point operations). Notably, this trigger is not linked to dual-use foundation models. This language is much broader than the scope defined in EO 14110 because its sole focus is on computing power used to train an AI model, which is not a true indicator of whether an AI model is a dual-use foundation model that poses a significant risk to national security.<br/><br/>It is important for BIS to focus its limited resources on dual-use foundation models that pose actual national security concerns, and not unnecessarily burden industry. BIS should therefore revise proposed section 702.7(a)(1)(i), in the relevant part, to comport with the authority and intent stated at section 4.2(a)(i) of the EO 14110, as follows [recommended edits in CAPS]:<br/><br/>&ldquo;(i) Conducting any AI model training run FOR A DUAL-USE FOUNDATION MODEL using more than 10^26 computational operations (e.g., integer or floating-point operations);&rdquo;","[('image', 'https://downloads.regulations.gov/BIS-2024-0047-0015/attachment_1.png')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0015,
comment,2024-10-22T19:46:34Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0043,Future of Life Institute,,,Public Comment 38. Other. Future of Life Institute,"Request for Comment attached as PDF below <br/>Organization: Future of Life Institute <br/>Point of Contact: Hamza Chaudhry, hamza@futureoflife.org","[('RfC Future of Life Institute BIS-2024-0047', 'https://downloads.regulations.gov/BIS-2024-0047-0043/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0043,"The Future of Life Institute (FLI) provided recommendations in response to the BIS rule for reporting requirements on AI models and computing clusters. They suggested expanding reporting to include safety and security practices, requiring disclosure of unforeseen system behaviors promptly, including anonymized evaluator profiles in red-teaming reports, creating a confidential reporting mechanism for workers, establishing a registry of advanced chips, and outlining standards for chip verification. FLI emphasized the importance of robust reporting to enhance national security measures in AI development."
comment,2024-10-22T19:46:36Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0046,Machine Intelligence Research Institute,,,Public Comment 41. Other. Machine Intelligence Research Institute,"Please see the attached file, which contains a letter with our comments. ","[('Comments on BIS reporting requirements', 'https://downloads.regulations.gov/BIS-2024-0047-0046/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0046,"The Machine Intelligence Research Institute (MIRI) supports reporting requirements for advanced AI models and computing clusters to enhance transparency and preparedness for rapid advancements. They suggest ad hoc reporting for significant developments, updating reporting frequency based on AI progress, and tiered confidentiality for sensitive information. MIRI recommends including details on computing clusters, emergency response protocols, AI development practices, model capabilities, and developer security measures in the reporting requirements. They offer to provide support and technical briefings on these topics. Contact: techgov@intelligence.org."
comment,2024-10-22T19:46:28Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0033,ITIF's Center for Data Innovation,,,Public Comment 28. Other. ITFI's Center for Data Innovation,"On behalf of the Center for Data Innovation, I am pleased to submit the attached response to the Bureau of Industry and Security&#39;s proposed rule.<br/><br/>Many thanks,<br/>Hodan Omaar<br/>Senior Policy Manager, Center for Data Innovation","[('Center for Data Innovation Comments - BIS Reporting Rule ', 'https://downloads.regulations.gov/BIS-2024-0047-0033/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0033,"The Center for Data Innovation responds to the Department of Commerce's proposed rule on reporting requirements for AI models. They advocate for a shift from compute-based to performance-based reporting to better assess AI risks. They suggest aligning with the AI Safety Institute's capabilities-based approach and adapting requirements to balance open-source and closed foundation models, as open-source projects may struggle with ownership and security reporting. They emphasize the need for flexibility to foster innovation in open-source AI projects."
comment,2024-10-22T19:46:25Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0027,Hewlett Packard Enterprise (HPE),,,Public Comment 20. U.S. Business. HPE,Please find attached comments from Hewlett Packard Enterprise on the proposed rule. Please note that both public and business confidential versions are attached.,"[('P Hewlett Packard Enterprise Comments on BIS NPRM re Reporting Requirements for AI Models and Compute Clusters ', 'https://downloads.regulations.gov/BIS-2024-0047-0027/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0027,The email address ai_reporting@bis.doc.gov is likely associated with the Bureau of Industry and Security (BIS) within the Department of Commerce. It may be used for reporting or communication related to artificial intelligence (AI) technologies and their potential impact on national security and trade.
comment,2024-10-22T19:46:20Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0019,,,Anonymous,Public Comment 13. Individual. Anonymous (2)- Part 6 of 7,"PUBLIC COMMENT CONTINUED<br/>RIN 0694-AJ55 <br/>October 11, 2024<br/><br/>VI. BIS SHOULD EXPLAIN HOW IT WILL SAFEGUARD PROPRIETARY INFORMATION PROVIDED BY RESPONDENTS IN RESPONSE TO BIS REQUESTS FOR INFORMATION.<br/><br/>In the proposed rule, &ldquo;BIS recognizes that the information collected through these reporting requirements is extremely sensitive.&rdquo;  Further, the proposed rule states that &ldquo;all information submitted to the Department under this rule will be treated as confidential and afforded all the protection of section 705(d) of the DPA.&rdquo; In addition, information provided in response to BIS questions is considered exempt from the Freedom of Information Act, 5 U.S.C. &sect; 552(b), and protected from disclosure under and 18 U.S.C. &sect; 1905.<br/><br/>Given the U.S. Government&rsquo;s obligations to safeguard information provided by industry in response to BIS requests, the highly competitive nature of AI development, the highly confidential and proprietary nature of the information that will be requested by BIS, the history of U.S. Government data breaches, and the irreparable harm that would be caused by leaks and/or by BIS sharing confidential and proprietary industry information, BIS should clarify how sensitive information to be provided by respondents will be safeguarded from competitors and other members of the public.<br/><br/>More specifically, BIS should answer the following questions in any final rule:<br/>1.  How BIS plans to have respondents transmit responses to BIS questions? <br/>2.  What security measures BIS will take to ensure that the information in industry member reports will be adequately secured while in transit to the government, on BIS&rsquo;s survey system, and at rest on government servers? <br/>3.  Under what situations and conditions BIS may share information in industry member reports with other government agencies, members of Congress, and any other third-party recipients? <br/>4.  Are there any circumstances in which BIS would share information in industry member reports with private third parties, to include government contractors?<br/>5.  How will BIS transmit information in industry member reports to third-party recipients? <br/>6.  What security measures will BIS require of third-party recipients to ensure that the recipients will adequately secure information in industry member reports while in transit and at rest?<br/>7.  What restrictions will BIS impose on third party sharing of information in industry member reports? <br/>8.  How will BIS verify whether third-party recipients are complying with restrictions on sharing information in industry member reports?","[('image', 'https://downloads.regulations.gov/BIS-2024-0047-0019/attachment_1.png')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0019,
comment,2024-10-22T19:46:37Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0047,Encode Justice,,,Public Comment 23. Other. Encode Justice,See attached file(s),"[('Encode Justice - Bureau of Industry and Security (BIS) Comment - 15 CFR Part 702', 'https://downloads.regulations.gov/BIS-2024-0047-0047/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0047,"Encode Justice supports the Bureau of Industry and Security's proposed reporting requirements for the development of advanced Artificial Intelligence models and clusters. They emphasize the importance of transparency for national security, efficient government adoption of AI, and protecting technologies from theft. They suggest clarifying thresholds for models trained on biological synthesis data and regularly reevaluating these thresholds to keep pace with technological advancements. Encode Justice believes that these rules, with suggested adjustments, will enhance American national security and public safety."
comment,2024-10-22T19:46:24Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0025,Convergence Analysis,,,Public Comment 18. Other. Convergence Analysis," Please refer to our uploaded files: <br/><br/>- Our Official Comment:<br/>&quot;Convergence Analysis Comment on Establishment of Reporting Requirements for the Development of Advanced Artificial Intelligence Models and Computing Clusters.pdf&quot; <br/><br/>- Our recently published report on frontier model reporting requirements, referred to in our comment: <br/>&quot;AI Model Registries - A Foundational Tool for AI Governance.pdf&quot;","[('Convergence Analysis Comment on Establishment of Reporting Requirements for the Development of Advanced Artificial Intelligence Models and Computing Clusters', 'https://downloads.regulations.gov/BIS-2024-0047-0025/attachment_1.pdf'), ('AI Model Registries - A Foundational Tool for AI Governance', 'https://downloads.regulations.gov/BIS-2024-0047-0025/attachment_2.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0025,"The document discusses the proposal for implementing national AI model registries as a foundational tool for AI governance. It explores the benefits, risks, design principles, and implementation of such registries. The aim is to provide governments with insight into frontier AI models, enable regulatory enforcement, develop new regulations, and foster public sector expertise in AI governance. Existing model registries in New York, China, EU, and the US are mentioned, highlighting the need for additional requirements to enhance governmental oversight. The emphasis is on minimizing regulatory burden, avoiding mandatory standards or licensing, and ensuring accuracy and utility in the registry content."
comment,2024-10-22T19:46:27Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0031,Information Technology Industry Council (ITI),,,Public Comment 26. Industry Association. Information Technology Industry Council,See attached file(s),"[('ITI Feedback on BIS AI Reporting Final', 'https://downloads.regulations.gov/BIS-2024-0047-0031/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0031,"The Information Technology Industry Council (ITI) supports the BIS proposed rule on reporting requirements for advanced AI models. They emphasize responsible AI development and suggest clarifying the purpose of information collection under the Defense Production Act. ITI recommends limiting access to sensitive information, establishing a consultative mechanism, and providing timely updates on technical parameters. They propose a 6-month reporting period instead of quarterly, with specific guidance for covered entities. ITI also suggests clarifying definitions for dual-use foundation models, training processes, and large-scale computing clusters to ensure precise reporting."
comment,2024-10-22T19:46:28Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0032,Recording Industry Association of America (RIAA),,,Public Comment 27. Industry Association. Recording Industry Association of America,See attached file(s),"[('RIAA Comments on BIS NPRM', 'https://downloads.regulations.gov/BIS-2024-0047-0032/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0032,"Susan Chertkof, on behalf of the Recording Industry Association of America, comments on the Department of Commerce's proposed rule on Advanced Artificial Intelligence Models and Computing Clusters. RIAA supports responsible AI development with reporting requirements to ensure compliance with laws, particularly intellectual property laws. They emphasize the need for detailed recordkeeping on training materials used for AI models to address concerns about safety, reliability, and legal risks. RIAA suggests transparency and documentation in line with NTIA and NIST recommendations, urging BIS to monitor unauthorized copyrighted content in training datasets. They stress the importance of protecting intellectual property in the AI industry."
comment,2024-10-22T19:46:33Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0041,OpenAI,,,Public Comment 36. U.S. Business. OpenAI,See attached file(s),"[('OpenAI Comment on BIS Proposed Rule (No. 240905-0242)', 'https://downloads.regulations.gov/BIS-2024-0047-0041/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0041,"In his submission to the Department of Commerce, Ben Rossen of OpenAI provides feedback on the proposed rule amending reporting requirements for advanced AI models and computing clusters. OpenAI suggests adjusting reporting frequency to every six months to reduce burden, streamlining notifications, specifying requests, ensuring information security, defining thresholds, and clarifying technical standards. They express concerns about continuous reporting burdens, ambiguous information requests, and the need for secure handling of sensitive information. OpenAI recommends modifying reporting schedules, streamlining subsequent reporting cycles, standardizing information requests, ensuring data security, and clarifying technical criteria for compute thresholds."
comment,2024-10-22T19:46:37Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0048,METR - Model Evaluation Threat Research,,,Public Comment 43. Other. METR- Model Evaluation Threat Research,See attached file(s),"[('METR_Comment_10-11-24', 'https://downloads.regulations.gov/BIS-2024-0047-0048/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0048,"METR, a research non-profit in Berkeley, supports the Bureau of Industry and Security's proposed reporting requirements on Advanced AI Models and Computing Clusters. They suggest cybersecurity measures for data protection and aligning red-teaming guidance with NIST AI 800-1 standards. METR emphasizes the importance of reporting hazardous capabilities evaluation results and provides suggestions for benchmarks and assessments in domains like biology, cyber attacks, self-replication, and autonomy. They believe these requirements are crucial for enhancing government oversight of advanced AI activities."
comment,2024-10-22T19:46:31Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0038,The Electronic Privacy Information Center (EPIC),,,Public Comment 33. Other. The Electronic Privacy Information Center,See attached file(s),"[('DOC BIS Proposed AI Rule - EPIC Comments', 'https://downloads.regulations.gov/BIS-2024-0047-0038/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0038,"The Electronic Privacy Information Center (EPIC) supports the Department of Commerce Bureau of Industry and Security's proposed rule on reporting requirements for advanced AI models. They emphasize the need for transparency, accountability, and risk assessment in AI development to ensure safe and reliable government AI use. EPIC highlights concerns about bias, accuracy, data origin, and security vulnerabilities in AI models. They recommend including detailed information in reporting requirements such as data curation processes, risk assessments, and audit documentation. EPIC's goal is to promote oversight and transparency for equitable and trustworthy government AI use."
comment,2024-10-22T19:46:17Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0014,,,Anonymous,Public Comment 13. Individual. Anonymous (2)- Part 1 of 7,"PUBLIC COMMENT<br/>RIN 0694-AJ55 <br/>October 11, 2024<br/><br/>The following comments and recommended revisions are provided below in response to the U.S. Department of the Commerce, Bureau or Industry and Security (BIS) proposed rule on &ldquo;Establishment of Reporting Requirements for the Development of Advanced Artificial Intelligence Models and Computing Clusters&rdquo; published on September 11, 2024, under 89 Fed. Reg. 73612.<br/><br/>This comment is being submitted in seven parts/sections due to the character limit on the Regulations.gov comment submission form.<br/><br/>I. BIS SHOULD PERFORM A COSTS-BENEFITS ANALYSIS OF THE PROPOSED REPORTING REQUIREMENTS<br/> <br/>As a preliminary matter, BIS should perform a sufficient costs-benefits analysis of the likely impacts of the proposed reporting requirements on U.S. technological leadership in AI.<br/><br/>Relevant to this analysis, a key conclusion from the agency&rsquo;s 1994 AI industrial base assessment found:<br/><br/>&ldquo;The United States leading position in AI is eroding as the government and companies in Japan, as well as in Western Europe, working together, have gained ground. In select areas of AI, Japan and Western Europe now surpass the U.S.&rdquo;<br/><br/>See Critical Technology Assessment of the Artificial Intelligence Sector (August 1994), available at www.bis.doc.gov/index.php/documents/technology-evaluation/33-critical-technology-assessment-of-u-s-artificial-intelligence-1994/file<br/><br/>In the proposed rule, BIS states that it needs ongoing quarterly reports for information &ldquo;that will allow the U.S. Government to determine whether action is necessary to stimulate development of dual-use foundation models or to support the development of specific types of models.&rdquo; However, the government is no longer a significant source of funding or other incentives for AI research and development, and it is unlikely to have sufficient resources to do so in an impactful way. This is because, since the agency&rsquo;s 1994 AI assessment, a fundamental shift in the marketplace has reshaped the AI research and development landscape. Specifically, compared to 1994, today&rsquo;s AI research and development is:<br/>&bull; reliant on funding by the commercial sector, which contributes billions upon billions of dollars towards these efforts;<br/>&bull; the focus of fierce commercial competition in the United States and abroad;<br/>&bull; in advanced stages of development by non-U.S. allied countries;<br/>&bull; significantly supported by non-U.S. engineers; and<br/>&bull; increasingly used in everything from online search tools, e-commerce, travel, and a wide array of other civilian applications.<br/><br/>Imposing ongoing quarterly reporting requirements, expanding export controls, imposing limits on academic funding by non-U.S. companies, and other limitations on AI research and development in the United States will incentivize companies to move research and development abroad. Further, based on lessons learned from export controls on the U.S. commercial satellite, semiconductor, and other industries, increased regulatory requirements are likely to lead the international community to exclude U.S. industry from the global marketplace of ideas necessary to maintaining U.S. technological leadership. BIS should therefore undertake a more careful consideration of the costs and benefits than is reflected in the proposed rule.","[('image', 'https://downloads.regulations.gov/BIS-2024-0047-0014/attachment_1.png')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0014,
comment,2024-10-22T19:46:15Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0011,Hacking Policy Council,,,Public Comment 10. Other. Hacking Policy Council,See attached file(s),"[('Hacking Policy Council - Comments to BIS re reporting requirements for advanced AI - 20241010', 'https://downloads.regulations.gov/BIS-2024-0047-0011/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0011,"The Hacking Policy Council (HPC) comments on the U.S. Department of Commerce's rulemaking for reporting requirements on advanced AI models. They support the focus on safety and security of dual-use foundational models but caution against disclosing sensitive information that may pose risks. HPC recommends revising the language to balance security concerns and protect sensitive information, establish robust legal protections, and clarify the scope of AI red-teaming activities to avoid burdening developers and inundating regulators with reports. They also highlight the importance of avoiding setting undesirable international precedents."
comment,2024-10-22T19:46:29Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0034,Anthropic PBC,,,Public Comment 29. U.S. Business. Anthropic,See attached file(s),"[('Anthropic Comment on BIS-2024-0047', 'https://downloads.regulations.gov/BIS-2024-0047-0034/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0034,"Anthropic, an AI safety and research company, supports the Department of Commerce's efforts in responsible AI development. They recommend adjusting reporting frequency to semi-annually to align with AI model training timelines and reduce administrative burdens. Anthropic suggests extending response times for surveys to accommodate smaller organizations and enhance data accuracy. They also emphasize the need for robust security measures to protect proprietary information shared with the government. Additionally, Anthropic proposes modifications to clarify definitions and ensure the protection of proprietary information while promoting AI innovation in the US."
comment,2024-10-22T19:46:23Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0024,U.S. Chamber of Commerce,,,Public Comment 17. Industry Association. U.S. Chamber of Commerce,See attached file(s),"[('CTEC_Comments_AI ModelsComputing_Commerce_Final', 'https://downloads.regulations.gov/BIS-2024-0047-0024/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0024,"The U.S. Chamber of Commerce expresses concerns about the burden of quarterly reporting requirements for AI models. They suggest annual reporting instead, citing the significant resources and coordination needed for compliance. The Chamber requests more clarity on operationalizing the reporting, confidentiality of sensitive information, and exemption from Freedom of Information Act requests. They aim to collaborate with the Department of Commerce to ensure reporting requirements support U.S. AI leadership without overwhelming companies."
comment,2024-10-22T19:46:19Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0017,,,Anonymous,Public Comment 13. Individual. Anonymous (2)- Part 4 of 7,"PUBLIC COMMENT CONTINUED<br/>RIN 0694-AJ55 <br/>October 11, 2024<br/><br/>IV. THE COMPUTING CLUSTER REPORTING REQUIREMENT SHOULD ONLY APPLY WHEN A COMPUTING CLUSTER ACTUALLY EXCEEDS A STATED THRESHOLD AND NOT MERELY WHEN THERE IS A POTENTIAL TO EXCEED A THRESHOLD.<br/><br/>Section 4.2(a)(ii) of EO 14110 mandates that &ldquo;companies, individuals, or other organizations or entities that acquire, develop, or possess a potential large-scale computing cluster must report any such acquisition, development, or possession, including the existence and location of these clusters and the amount of total computing power available in each cluster.&rdquo;<br/><br/>The computing cluster reporting requirement should not apply when there is merely a potential to exceed a certain performance threshold because performance thresholds are most often not determined at the time of acquiring hardware or standing up a computing cluster (pre-build, or even semi build). To the contrary, U.S. covered persons generally do not know whether or not hardware being installed would meet a threshold until after a cluster is built, and all the hardware is up and running at a datacenter.  While they may have estimates or some plans regarding how the computing cluster will be used, they often get updated and changed as it currently takes anywhere between 18-24 months for a new data center to come online.<br/><br/>As proposed, section 702.7(a)(1)(ii) requires quarterly reporting where a covered U.S. person &ldquo;engages in, or plans, within six months, to engage in&rdquo; activities that involve &ldquo;[a]cquiring, developing, or coming into possession of a computing cluster that&rdquo; exceeds stated thresholds. Nevertheless, the inconsistency between the language in EO 14110 (which refers to a &ldquo;potential large-scale computing cluster&rdquo;) and proposed section 702.7(a)(1)(ii) could cause over-reporting by companies with resources that could potentially be networked to exceed the stated performance parameters.<br/><br/>BIS should therefore revise section 702.7(a)(1)(ii) to clarify that the computing cluster reporting requirement only applies when a covered person has &ldquo;knowledge&rdquo; as defined in EAR section 772.1 that a computing cluster actually exceeds stated thresholds, and not when there is merely the potential to exceed a threshold.<br/><br/>More specifically, BIS should revise proposed section 702.7(a)(1)(ii) as follows [recommended edits in CAPS]:<br/><br/>(ii) Acquiring, developing, or coming into possession of a computing cluster that THE COVERED PERSON KNOWS has a set of machines transitively connected by data center networking of greater than 300 Gbit/s and having a theoretical maximum greater than 10^20 computational operations ( e.g., integer or floating-point operations) per second (OP/s) for AI training, without sparsity.","[('image', 'https://downloads.regulations.gov/BIS-2024-0047-0017/attachment_1.png')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0017,
comment,2024-10-22T19:46:31Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0039,The Abundance Institute,,,Public Comment 34. Other. The Abundance Institute,"See the attached document for the comments of Neil Chilson, Head of AI Policy at the Abundance Institute, arguing that because Section 4.2 of the EO exceeds DPA authority, the proposed rule is unauthorized. It is also contrary to existing BIS rules. BIS should not adopt it. <br/><br/>However, if BIS does pursue reporting requirements it should do so by periodically issuing one-time surveys through the normal survey process, to parties identified by BIS. At a minimum, BIS must offer a full-fledged legal justification for how the proposed rule complies with the DPA and the existing BIS rules, and further detail how the rule complies with the PRA and RFA.<br/>","[('Comments of the Abundance Institute - BIS Reporting Requirements (FINAL)', 'https://downloads.regulations.gov/BIS-2024-0047-0039/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0039,"The Abundance Institute, represented by Neil Chilson, critiques the Bureau of Industry and Security's (BIS) proposed rule on regulating AI models and computing clusters under the Defense Production Act (DPA) and Executive Order (EO). They argue that the proposed rule is unauthorized, unnecessary, and conflicts with the DPA and existing BIS regulations. The Institute suggests that if reporting requirements are to be implemented, they should be done through standard procedures, with clear legal justifications and compliance with relevant acts like the Paperwork Reduction Act (PRA) and Regulatory Flexibility Act (RFA)."
comment,2024-10-22T19:46:16Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0013,Group 42 Holding Ltd,,,Public Comment 12. Foreign Business. G42,Group 42 Holding Ltd respectfully submits the attached comment letter regarding BIS-2024-0047-0001.<br/><br/>,"[('BIS-2024-0047 Comment Letter _G42', 'https://downloads.regulations.gov/BIS-2024-0047-0013/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0013,"G42 Holding Ltd, an AI and cloud computing company, supports the US Department of Commerce's proposed rule on reporting requirements for advanced AI models and computing clusters. They request clarification on the scope of covered persons subject to reporting, suggesting a revised definition of ""covered U.S. persons."" G42 is concerned that the current proposal may impose reporting requirements on individual US nationals working for companies, leading to overlapping obligations. They recommend that reporting responsibilities lie with the covered entity, not its employees."
comment,2024-10-22T19:46:38Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0049,Center for AI Risk Management & Alignment,,,Public Comment 44. Other. Center for AI Risk Management & Alignment,"Establishment of Reporting Requirements for the Development of Advanced Artificial Intelligence Models and Computing Clusters:<br/><br/>Response from the Center for AI Risk Management &amp; Alignment (CARMA) to the Bureau of Industry and Security (BIS) Request for Public Comment<br/><br/>Center for AI Risk Management &amp; Alignment (CARMA)<br/><br/>October 11, 2024<br/><br/>The Center for AI Risk Management &amp; Alignment (CARMA) appreciates the opportunity to provide feedback on the Bureau of Industry and Security (BIS) rule for the Establishment of Reporting Requirements for the Development of Advanced Artificial Intelligence Models and Computing Clusters, pursuant to the Executive Order on Safe, Secure and Trustworthy AI (E.O. 14110). This rule is a promising step toward ensuring transparency and accountability from AI companies working on the most advanced &ldquo;dual use foundation models&rdquo; while securing the safety and competitiveness of the U.S. defense industrial base. <br/><br/>Our response to this Request for Comment aims to support BIS in aligning the reporting requirements with the intended goals of the Executive Order, ensuring robust protection from advanced AI risks. We emphasize the importance of adaptive, regulatory frameworks, robust risk assessments, and the need for secure reporting channels to enable<span style='padding-left: 30px'></span>whistleblower protection. These recommendations are designed to support BIS in mitigating risks while ensuring societal resilience.<br/><br/>CARMA is a technical governance thinktank focused on developing a more accurate mapping of risks from advanced AI systems and characterizing novel policy approaches to ensure societal safety and security.<br/><br/>Overview<br/><br/>AI has quickly become an integral part of large segments of the economy and industry, including those that are crucial to U.S. national defense. This includes manufacturers of military equipment that use AI models &ldquo;to enhance the maneuverability, accuracy, and efficiency of equipment,&rdquo; tools central to intelligence collection, and secondary components that extend the capabilities of the U.S. defense industrial base (BIS-2024-0047). Whether this information is actionable for national defense depends largely on the accuracy, robustness, and reliability of the reporting from model developers. <br/><br/>In support of E.O. 14110, which requires reporting from companies planning to develop dual use foundation models, and BIS&rsquo;s authorities under the Defense Production Act (DPA), this comment seeks to ensure that the Department of Commerce has the greatest possible visibility into potential risks or indicators of unexpected behavior from developers of advanced general-purpose AI systems. Our six key recommendations include:<br/><br/>Significant Activity Reporting (SAR): Amend reporting requirements to include unscheduled updates on significant events like technological breakthroughs or unexpected failures, ensuring timely notifications of emergent capabilities and potential risks outside the quarterly schedule.<br/><br/>Secure Channel for Anonymous Reporting: Establish a secure, anonymous channel to report concerns over unsafe practices, vulnerabilities, or emergent capabilities, allowing critical information to be shared without fear of retribution and ensuring timely updates on potential security threats.<br/><br/>Comprehensive Risk Assessment and Independent Validation: Require companies to conduct thorough pre-deployment risk assessments and provide red-teaming data to BIS for independent validation and verification, allowing an additional layer of security.<br/><br/>Monitoring Large Compute Clusters: Establish a registration and licensing system for large-scale compute clusters, providing BIS with the means to monitor the development of powerful AI systems while developing alternative, adaptive approaches to monitor novel AI paradigms.<br/><br/>On-Chip Compute Governance: Implement on-chip governance mechanisms, such as delay-based geolocation, to verify chip locations, enforce export controls, and monitor the lifecycle of model development, ensuring compliance with national security regulations.<br/><br/>Metrics to Track Evolving AI Paradigms: Convene expert panel to devise tractable metrics beyond compute-based thresholds to account for evolving AI paradigms like decentralized and inference-based compute. <br/><br/>The majority of this comment focuses on recommendations under the mandatory notifications section (1. Quarterly Notification Schedule), as this is the most crucial short-term path to obtaining timely threat information. <br/><br/>See the attachment for the more detailed response. <br/>","[('RFC Center for AI Risk Management and Alignment - BIS-2024-0047', 'https://downloads.regulations.gov/BIS-2024-0047-0049/attachment_1.pdf'), ('RFC Center for AI Risk Management and Alignment BIS-2024-0047', 'https://downloads.regulations.gov/BIS-2024-0047-0049/attachment_2.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0049,"CARMA supports the Bureau of Industry and Security's rule on reporting requirements for advanced AI models. They emphasize the importance of transparency, risk assessments, and secure reporting channels, recommending amendments for unscheduled updates on significant events, secure channels for anonymous reporting, comprehensive risk assessments, monitoring of large compute clusters, on-chip compute governance, and metrics for evolving AI paradigms. They stress the need for adaptive regulatory frameworks to mitigate risks and ensure societal resilience. CARMA aims to align reporting requirements with the goals of the Executive Order on Safe, Secure, and Trustworthy AI."
comment,2024-10-22T19:46:29Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0035,AE Studio,,,Public Comment 30. U.S. Business. AE Studio,"We are AE Studio, a bootstrapped 150+ person data science, dev, and design consultancy. We reinvest profits into impact-focused foundational research, like neurotechnology and AI alignment, with the mission to increase human agency. <br/><br/>Our company works with frontier models across a wide array of clients within and beyond the tech sector, from the largest corporations to startups outsourcing their first technical projects to us, across a wide range of applications. To survive in our industry, we excel in our client work, with the best technical talent keeping up to date with the cutting edge of AI capabilities.<br/><br/>We are thankful to the Bureau of Industry and Security for their work concerning the future of AI. We believe AI has a highly uncertain future, and in some possible scenarios, perhaps inevitably, advanced AI models will be immensely capable and essential for national security and for the flourishing of our economy. <br/><br/>But the possible risks need to be managed. We should not entirely trust our future, the next nuclear technology, to the private sector, yet we should not also preemptively stifle essential innovation. We must defensively accelerate, and America must win the AI race, should there be one.<br/><br/>Monitoring the state of the art in the AI labs of America is the only way the US will be able to ensure we both: lead on the technology, and mitigate risks from the technology. Doing so with minimal friction such that we perfectly balance safety with winning, is our task.<br/><br/>Overview<br/>Enhancing Reporting Requirements for Dual-Use Foundation Model Developers<br/><br/>We present several proposals to strengthen the effectiveness and reliability of reporting requirements for entities developing dual-use foundation models. Our focus is on recommendations that the Bureau of Industry and Security (BIS) can implement within its current authority, prioritizing ideas that require minimal additional resources.<br/><br/>Key Recommendations<br/><br/>1. Establish a Protected/Anonymous Reporting Channel: Create a secure mechanism for employees of entities developing dual-use foundation models to report concerns. This channel (ai_reporting@bis.doc.gov) would allow staff to disclose:<br/>   a) Potential inaccuracies or misleading information in company reports to BIS<br/>   b) Safety and reliability issues related to dual-use foundation models<br/>   c) Activities or risks that may impact U.S. national security<br/><br/>   Ideally, this platform should be both protected (prohibiting retaliation) and anonymous. If protection is unfeasible, an anonymous system would still be valuable. Entities should confirm in their reports that employees are aware of this mechanism and that company policies do not hinder its use.<br/><br/>2. Implement Regular Employee Interviews: Conduct quarterly interviews with staff from entities producing dual-use foundation models. BIS would select interviewees from various teams to gather diverse insights. These conversations would cover model capabilities, safety and security concerns, and predictions about AI advancements that could pose new safety and security risks.<br/><br/>3. Require Capability Forecasts: In addition to red-team testing reports, companies should provide their best estimates of when they or others might develop dual-use foundation models with specific security-relevant capabilities. This would assist the U.S. industrial base and defense sector in making informed predictions about future AI advancements and their defense implications.<br/><br/>4. Mandate a Summary Form for Non-Experts: Alongside detailed reports, require entities to submit a concise Summary Form accessible to non-technical audiences. This form would highlight the most critical defense-relevant information in a clear, easily digestible format.<br/><br/>5. Modify Notification Conditions: Require entities to inform BIS of significant capability improvements that present immediate security risks within 5 days of discovery. This ensures BIS is promptly notified of crucial advancements between quarterly reports.<br/><br/>We suggest applying these recommendations to all entities developing dual-use foundation models. However, if this proves impractical, focusing on the top 10 entities would still yield valuable information for U.S. industrial and national defense interests.<br/>","[('AE Studio BIS RFC', 'https://downloads.regulations.gov/BIS-2024-0047-0035/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0035,"AE Studio, a data science consultancy, supports the Department of Commerce's efforts on AI regulation. They stress the importance of managing risks associated with advanced AI models and propose measures like a protected reporting channel, regular employee interviews, capability forecasts, concise summary forms, and amended notification conditions. These recommendations aim to enhance the effectiveness of reporting requirements for entities developing dual-use foundation AI models, ensuring national security and innovation are balanced."
comment,2024-10-22T19:46:13Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0006,Center for Progress,,Calzada,Public Comment 5. Other. Center for Progress.,See attached file(s),"[('Bureau of Industry and Security (BIS) comment (Dual use models) ', 'https://downloads.regulations.gov/BIS-2024-0047-0006/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0006,"Chamber of Progress, a tech industry association, supports a balanced regulatory approach by the U.S. Bureau of Industry and Security (BIS) for AI models. They caution against overly prescriptive frameworks that stifle innovation, advocating for diverse foundation models. They argue against broad regulations that harm smaller players and suggest focusing on specific risks rather than blanket reporting. While supporting responsible AI development, they urge BIS to reconsider aspects of the rule to avoid stifling competition and innovation, promoting a balanced approach for maintaining U.S. competitiveness in AI."
comment,2024-10-22T19:46:30Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0037,CTIA – The Wireless Association,,,Public Comment 32. Industry Association. CTIA,Please see the attached PDF,"[('CTIA BIS comment letter 10.11.24 vF', 'https://downloads.regulations.gov/BIS-2024-0047-0037/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0037,CTIA supports the Department of Commerce's goal of ensuring the US government has necessary information on developing advanced AI models. They emphasize the importance of balancing AI innovations with potential risks and staying ahead of bad actors. CTIA suggests clarifying reporting requirements to focus on entities using computing clusters for AI training activities specifically. They argue that including data center operators not engaged in AI training would not align with national defense goals. CTIA recommends limiting reporting requirements to capture relevant information from companies involved in developing and training dual-use foundation models.
comment,2024-10-22T19:46:26Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0029,TechNet,,,Public Comment 24. Industry Association. Tecnet,See attached file(s),"[('FINAL TechNet Comment to BIS re Foundation Model Reporting', 'https://downloads.regulations.gov/BIS-2024-0047-0029/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0029,"TechNet, a national network of technology CEOs and executives, expressed concerns to the Bureau of Industry and Security (BIS) regarding the proposed rule on reporting requirements for advanced AI models and computing clusters. They argued that quarterly reporting is too frequent and burdensome, recommending six-month or annual reporting instead. TechNet also suggested clearer criteria for reporting, revisions to the definition of dual-use foundation models, secure submission methods, and a reevaluation of computational thresholds for reporting requirements. They emphasized the need for flexibility and clarity in determining which AI models fall under the oversight of the rule."
comment,2024-10-22T19:46:24Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0026,AdvaMed,,,Public Comment 19. U.S. Business. AdvaMed Imaging,See attached file(s),"[('AdvaMed Imaging - AIC - ISB Proposed Rule - 20241011 - FINAL', 'https://downloads.regulations.gov/BIS-2024-0047-0026/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0026,"AdvaMed, representing medical technology manufacturers, requests FDA-regulated AI-based medical devices be exempt from the proposed rule due to existing FDA oversight ensuring safety and efficacy. They argue additional reporting requirements would create redundancy, delay patient access to innovations, and burden developers. AdvaMed highlights FDA's robust regulatory framework for AI devices, including premarket review and post-market surveillance. They emphasize flexibility in FDA processes to accommodate AI advancements and ensure patient safety, advocating for exemptions to prevent stifling innovation while maintaining regulatory standards."
comment,2024-10-22T19:46:27Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0030,Computer & Communications Industry Association,,,Public Comment 25. Industry Association. Computer and Communications Industry Association,See attached file.,"[('2024-10-11 CCIA Comments to BIS on Reporting Requirements for Advanced AI Models and Computing Clusters', 'https://downloads.regulations.gov/BIS-2024-0047-0030/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0030,"The Computer & Communications Industry Association (CCIA) submitted comments to the Department of Commerce regarding reporting requirements for advanced AI models and computing clusters. CCIA recommended adopting semi-annual or annual reporting schedules, detailing information security protocols, exempting reporting information from FOIA requests, establishing consistent guidance for measuring and reporting compute, and developing the standard questionnaire through open consultation. CCIA emphasized the need for balanced data collection, protection of proprietary information, and collaboration with industry for refining the reporting process. Gabriel Delsol, CCIA's Policy Manager, expressed willingness to collaborate further on these issues."
