commentOrDocument,modifyDate,docketId,commentOnDocumentId,id,organization,firstName,lastName,title,comment,attachments,link
document,2024-10-14T01:00:58Z,BIS-2024-0047,,BIS-2024-0047-0001,,,,Reporting Requirements for the Development of Advanced Artificial Intelligence Models and Computing Clusters,,"[('Reporting Requirements for the Development of Advanced Artificial Intelligence Models and Computing Clusters', 'https://downloads.regulations.gov/BIS-2024-0047-0001/content.pdf')]",https://api.regulations.gov/v4/documents/BIS-2024-0047-0001
comment,2024-10-22T19:46:11Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0003,Americans for Prosperity Foundation,,,Public Comment 2. Other. Americans for Prosperity,See attached file(s),"[('2024.10.07 AFPF Regulatory Comment to BIS on DPA AI Reporting Requirements', 'https://downloads.regulations.gov/BIS-2024-0047-0003/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0003
comment,2024-10-22T19:46:30Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0036,Mozilla,,,Public Comment 31. U.S. Business. Mozilla,See attached file(s),"[('BIS_Reporting_Requirements_Response_Submission_2024-10-11', 'https://downloads.regulations.gov/BIS-2024-0047-0036/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0036
comment,2024-10-22T19:46:12Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0004,IBM,,,Public Comment 3. U.S. Business. IBM,See attached file(s),"[('RFC on BIS AI Rulemaking - Final', 'https://downloads.regulations.gov/BIS-2024-0047-0004/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0004
comment,2024-10-22T19:46:14Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0008,,,Madkour,"Public Comment 7. Individual. Anthony Barrett, Nada Madkour, Evan Murphy, Jessica Newman","To the Bureau of Industry and Security,<br/><br/>Thank you for the opportunity to submit comments in response to the proposed rule Establishment of Reporting Requirements for the Development of Advanced Artificial Intelligence Models and Computing Clusters (89 FR 73612) (RIN 0694-AJ55). We offer the following submission for your consideration. My colleagues and I are researchers affiliated with UC Berkeley, with expertise in AI research and development, safety, security, policy, and ethics (while we collaborated in drafting this comment, it is submitted in a personal capacity). <br/><br/>We agree with the text in the proposed rule that &ldquo;the U.S. Government needs information about how many U.S. companies are developing, have plans to develop, or have the computing hardware necessary to develop dual-use foundation models, as well as information about the characteristics of dual-use foundation models under development,&rdquo; and that &ldquo;the integration of AI models into the defense industrial base also requires the U.S. Government to take actions as needed to ensure that dual-use foundation models operate in a safe and reliable manner.&rdquo; Our research underscores that &ldquo;these models may operate in unpredictable or unreliable ways, potentially resulting in dangerous accidents,&rdquo; and we strongly agree that the U.S. Government needs information about how companies have tested the safety and reliability of their models, including red-teaming results and risk mitigation efforts. (See, e.g., our report &ldquo;Benchmark Early and Red Team Often: A Framework for Assessing and Managing Dual-Use Hazards of AI Foundation Models&rdquo;, Barrett et al. 2024.) Furthermore, we strongly agree that the U.S. Government must minimize the vulnerability of dual-use foundation models to cyberattacks, which will require information about companies&rsquo; cybersecurity measures, resources, and practices.<br/><br/>One key aspect of the proposed rule is that it provides some basic hard-law requirements for reasonable risk-management steps by developers of dual-use foundation models. Several leading developers currently carry out important risk management steps on a voluntary basis, and soft-law voluntary AI risk management standards serve a valuable role in AI governance. However, reasonable hard-law requirements and enforcement provide additional, worthwhile incentives for developers of dual-use foundation models to take important risk-management steps that can affect public safety, such as to help prevent bio- or cyber-attacks substantially assisted by malicious misuse of dual-use foundation models. (See, e.g., our &ldquo;Policy Brief on AI Risk Management Standards for General-Purpose AI Systems (GPAIS) and Foundation Models&rdquo;, Barrett, Newman et al. 2023). <br/><br/>We support the requirements and the outlined approach defined in the Reporting Requirements, including quarterly reporting from companies developing dual-use foundation models or large-scale computing clusters. The quarterly notification schedule is appropriate because it allows for extremely minimal reporting in instances where companies have no notable changes. Given the pace of change in the field, this frequency is warranted and important for timely information gathering. <br/><br/>We also encourage consideration of refinements to the collection threshold for dual-use foundation models. Close monitoring of new models, and trends in hardware and algorithmic efficiency, may indicate that substantial dual-use capabilities could be present in models with training runs utilizing lower or higher amounts of computational operations than the currently proposed thresholds. <br/><br/>Our best,<br/><br/>Anthony Barrett, Ph.D., PMP<br/>Visiting Scholar<br/>AI Security Initiative, Center for Long-Term Cybersecurity, UC Berkeley<br/><br/>Nada Madkour, Ph.D.<br/>Non-Resident Research Fellow<br/>AI Security Initiative, Center for Long-Term Cybersecurity, UC Berkeley<br/><br/>Evan R. Murphy<br/>Non-Resident Research Fellow<br/>AI Security Initiative, Center for Long-Term Cybersecurity, UC Berkeley<br/><br/>Jessica Newman<br/>Director<br/>AI Security Initiative, Center for Long-Term Cybersecurity, UC Berkeley<br/>Co-Director<br/>AI Policy Hub, UC Berkeley<br/><br/>References <br/>Anthony M. Barrett, Krystal Jackson, Evan R. Murphy, Nada Madkour, Jessica Newman (2024). Benchmark Early and Red Team Often: A Framework for Assessing and Managing Dual-Use Hazards of AI Foundation Models. arXiv preprint, https://arxiv.org/abs/2405.10986<br/><br/>Anthony M. Barrett, Jessica Newman, and Brandie Nonnecke (2023) Policy Brief on AI Risk Management Standards for General-Purpose AI Systems (GPAIS) and Foundation Models. UC Berkeley Center for Long-Term Cybersecurity, https://cltc.berkeley.edu/publication/policy-brief-on-ai-risk-management-standards-for-general-purpose-ai-systems-gpais-and-foundation-models/ <br/><br/>Attached is a PDF copy of our comment including links to the cited resources. ","[('Comment on Development of Advanced Artificial Intelligence Models and Computing Clusters (RIN 0694-AJ55) NMadkour', 'https://downloads.regulations.gov/BIS-2024-0047-0008/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0008
comment,2024-10-22T19:46:12Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0005,Center for AI Policy,,,Public Comment 4. Other. Center for AI Policy,See attached file(s).,"[('RFC _ Reporting Requirements', 'https://downloads.regulations.gov/BIS-2024-0047-0005/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0005
comment,2024-10-22T19:46:10Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0002,,,Renner,Public Comment 1. Individual. Erik Renner. 09/16/24,See attached file(s),"[('Commnet on Reporting Requirements for AI', 'https://downloads.regulations.gov/BIS-2024-0047-0002/attachment_1.docx')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0002
comment,2024-10-22T19:46:18Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0016,,,Anonymous,Public Comment 13. Individual. Anonymous (2)- Part 3 of 7,"PUBLIC COMMENT CONTINUED<br/>RIN 0694-AJ55 <br/>October 11, 2024<br/><br/>III. QUARTERLY REPORTING WOULD IMPOSE EXTREME BURDENS THAT ARE NOT SUPPORTED BY THE STATED GOALS OF THE PROPOSED RULE.<br/><br/>The proposed rule would require companies that are (or will be) engaged in covered activities to submit reports on a quarterly basis. BIS states that these reporting requirements &ldquo;are expected to apply to only a small number of entities&rdquo; and estimates the number of respondents that exceed the reporting thresholds for models and computing clusters is between zero and 15 companies. At the same time BIS provides &ldquo;an estimated burden of 5,000 hours per year aggregated across all new respondents.&rdquo; This signals an extremely burdensome compliance obligation per respondent that would effectively mean that respondents are in a constant state of preparing reports, submitting reports, and responding to questions from BIS regarding reports.<br/><br/>Although BIS proposes to allow additions, updates or changes to the information provided on previous surveys submitted by a respondent, this does not alleviate the burden on respondents because they must still expend significant employee time and resources to determine whether such updates are required while at the same time evaluating their ongoing reporting requirements and respond to BIS questions. This is especially true given the detailed and lengthy nature of information normally required by BIS in industry surveys.<br/><br/>The proposed rule does not explain why quarterly reporting, or even annual reporting, is necessary instead of one-time reports. As noted above, BIS states that it needs quarterly reports for information &ldquo;that will allow the U.S. Government to determine whether action is necessary to stimulate development of dual-use foundation models or to support the development of specific types of models.&rdquo; However, this is similar to the rationales provided for other industrial base surveys, including those in the U.S. microelectronics and space industries as well as BIS&rsquo;s previous survey of the U.S. AI industry which addressed areas of national security concern, but only involved a one-time reporting requirement.","[('image', 'https://downloads.regulations.gov/BIS-2024-0047-0016/attachment_1.png')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0016
comment,2024-10-22T19:46:19Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0018,,,Anonymous,Public Comment 13. Individual. Anonymous (2)- Part 5 of 7,"PUBLIC COMMENT CONTINUED<br/>RIN 0694-AJ55 <br/>October 11, 2024<br/><br/>V. BIS SHOULD ELIMINATE AND/OR CLARIFY EMPLOYEE REPORTING OBLIGATIONS.<br/><br/>AI TRAINING RUN REPORTING<br/><br/>The AI training run reporting requirements are broader than the mandate in EO 14110 and should be revised to be consistent with that mandate. Section 4.2(a)(i) of EO 14110, directs the Secretary of Commerce to require &ldquo;Companies developing or demonstrating an intent to develop potential dual-use foundation models to provide the Federal Government, on an ongoing basis, with information, reports, or records&hellip;&rdquo;  The AI model training run reporting requirement at section 702.7(a)(1)(i), however, extends to &ldquo;covered U.S. persons,&rdquo; which per proposed section 701.7(c) would be defined to include any individual U.S. citizen, lawful permanent resident, or any person (individual) located in the United States.<br/><br/>Insofar as proposed section 702.7(a)(i) would require employees to report AI model training runs by their company, it is inconsistent with section 4.2(a)(i) of EO 14110, which directs the Secretary of Commerce to require &ldquo;Companies developing or demonstrating an intent to develop potential dual-use foundation models to provide the Federal Government, on an ongoing basis, with information, reports, or records&hellip;&rdquo;  In addition to going beyond the mandate of EO 14110, applying the reporting requirement to individual employees appears to be beyond the stated policy intent, which is focused on the U.S. industrial base.<br/><br/>BIS should therefore revise proposed section 702.7(a)(1)(i) to reflect that the AI model training reporting requirement is triggered and reportable by the U.S. organization, company, or corporation engaged in the applicable activity [recommended edits in CAPS]:<br/><br/>(a) Reporting Requirements<br/>(1) As set forth below, U.S. Covered persons or U.S. organizations, companies, and corporations are required to submit a notification to the Department by emailing ai_reporting@bis.doc.gov on a quarterly basis as defined in paragraph (a)(2) of this section if the relevant party engages in, or plans, within six months, to engage in &lsquo;applicable activities,&rsquo; defined as follows:<br/>(i) US ORGANIZATIONS, COMPANIES, AND CORPORATIONS [c]onducting any AI model training run using more than 10^26 computational operations (e.g., integer or floating-point operations);<br/><br/>At a minimum, if BIS is unable to make the revision above, BIS should clarify that reports on AI model training are only required for U.S. entities, and not for U.S. person employees of U.S. or non-U.S. entities, even if they are involved in AI model training in the course of their employment.<br/><br/>COMPUTER CLUSTER REPORTING<br/><br/>Proposed section 702.7(a)(ii) requires reporting by both companies and individuals who acquire, develop, or come into possession of a computing cluster exceeding specified thresholds.  While consistent with the EO 14110 mandate at Section 4.2(ii) which instructs the Secretary of Commerce to require &ldquo;Companies, individuals, or other organizations or entities that acquire, develop, or possess a potential large-scale computing cluster to report any such acquisition, development, or possession, including the existence and location of these clusters and the amount of total computing power available in each cluster,&rdquo; the proposed rule is broader than BIS&rsquo;s statement in the preamble where it describes that it is &ldquo;exercising its DPA authority, . . . to collect information from U.S. companies that are developing, have plans to develop, or have the computing hardware necessary to develop dual-use foundation models.&rdquo;<br/><br/>To the extent that BIS intends to require computing cluster reporting by individual U.S. persons, BIS should clarify that the requirement does not apply to individual employees of U.S. companies engaged in such activities and should provide guidance on scope of the individual reporting requirements. Such guidance should, at a minimum, confirm that:<br/>&bull;  An employee is not required to submit a report when his/her company has already submitted a report on the applicable activity to BIS.<br/>&bull;  An individual only has a reporting obligation when they are acting on their own behalf.<br/>&bull;  An employee executing their non-discretionary duties (e.g., processing a procurement order; installing or servicing hardware) is not engaged in the acquisition, development, or gaining possession of a computing cluster as contemplated in proposed section 702.7(a)(ii).<br/>&bull;  A U.S. person&rsquo;s mere use of a computing cluster located outside the United States that exceeds a stated threshold does not constitute the acquisition, development, or possession of a computing cluster.","[('image', 'https://downloads.regulations.gov/BIS-2024-0047-0018/attachment_1.png')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0018
comment,2024-10-22T19:46:14Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0009,,,Belmona,Public Comment 8. Individual. Amanda Belmona,"Dear Thea D. Rozman Kendler, <br/><br/>I support the proposed rule establishing reporting requirements for developing advanced artificial intelligence (AI) models and computing clusters. As AI continues to play an increasingly significant role in various sectors, including healthcare, finance, and national security, it is crucial to implement oversight mechanisms that ensure responsible development and deployment of these technologies. This proposed rule will provide necessary transparency, helping mitigate AI risks, such as bias, ethical concerns, and potential misuse.<br/>The establishment of reporting requirements will not only enhance accountability among developers and contribute to a more comprehensive understanding of AI&rsquo;s societal impacts. We can facilitate better collaboration between government agencies, private industry, and academic institutions by requiring developers to disclose information about their AI models and computing resources. Research indicates that transparent AI practices can increase public trust and acceptance of AI technologies (Nabavi &amp; Browne, 2023). Furthermore, studies have shown that organizations that adopt transparent AI practices are more likely to foster inclusive innovation, ensuring that diverse perspectives are considered in the development process (West et al., 2019). Additionally, implementing these reporting requirements aligns with global best practices for AI governance. The OECD&rsquo;s &ldquo;Principles on Artificial Intelligence&rdquo; emphasize the importance of transparency and accountability in AI systems, which can help build a solid framework for ethical AI development (OECD, 2024, pg 6). By adopting similar reporting standards, the U.S. can position itself as a leader in ethical AI practices and ensure that innovations benefit society while addressing potential risks.<br/>While some argue that these reporting requirements could stifle innovation or impose unnecessary burdens on developers, it is essential to recognize that transparency and responsible development do not have to come at the expense of innovation. Instead, these requirements can be a foundation for fostering ethical practices, leading to more robust and reliable AI solutions. We can address societal concerns by prioritizing responsible AI development while encouraging progress in this transformative field. I strongly support the proposed reporting requirements for advanced AI models and computing clusters. Implementing these measures will enhance accountability, promote ethical development, and help ensure that AI technologies benefit society. <br/><br/>Sincerely,<br/>Amanda Belmona<br/><br/>References:<br/>Nabavi, E., &amp; Browne, C. (2023). Leverage zones in Responsible AI: towards a systems thinking conceptualization. Humanities and Social Sciences Communications, 10(1). https://doi.org/10.1057/s41599-023-01579-0<br/>West, S.M., Whittaker, M. &amp; Crawford, K. (2019). Discriminating Systems: Gender, Race, and Power in AI. AI Now Institute. https://ainowinstitute.org/publication/discriminating-systems-gender-race-and-power-in-ai-2<br/>OECD (2024). OECD updates AI Principles to stay abreast of rapid technological developments. https://www.oecd.org/en/about/news/press-releases/2024/05/oecd-updates-ai-principles-to-stay-abreast-of-rapid-technological-developments.html<br/>",[],https://api.regulations.gov/v4/comments/BIS-2024-0047-0009
comment,2024-10-22T19:46:32Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0040,,,Anonymous,Public Comment 35. Individual. Anonymous,"This rule applies to companies who are working with Dual Use foundation models. Dual use foundation models are trained wide range of data with tens of billions of parameters. These models can significantly impact every sphere of human life. The executive order &ldquo;Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence&rdquo; (E.O. 14110) set forth the rules by which the burea of industry and security will monitor that AI models are being developed in a responsible way. This is definitely a double edged sword. At one point, we would want companies to have freedom to innovate but on the other hand we can see the potential negative consequences of large AI models in the wrong hands in terms of large scale cyberwarfare and crimes. As with most physical technologies that require patents and approvals from FDA etc, AI based models should also continue to have scrutiny especially as it relates to defense. I agree with the proposed rule under the executive order EO 14110.",[],https://api.regulations.gov/v4/comments/BIS-2024-0047-0040
comment,2024-10-22T19:46:13Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0007,WhoPoo App,,,Public Comment 6. US Business. WhoPoo App,"Biometrics don&#39;t work. Refer to the latest USCCR report on this, about facial recognition. The official recommendation is to NOT use biometrics because they have very high error rates among POC and the elderly, and there are currently no biometric data use policies posted on the DHS website to deter privacy concerns. See https://www.usccr.gov/reports/2024/civil-rights-implications-federal-use-facial-recognition-technology With respect to FRT accuracy and bias, the National Institute of Standards and Technology (NIST) <br/>testing is voluntary and represents laboratory&mdash;not real-world&mdash;results. Thus, NIST cannot say that <br/>its evaluated programs are accurately representative of the performance of all FRT deployed <br/>throughout the country. Algorithmic accuracy rates can vary widely among developers, but even with <br/>the highest-performing algorithms, tests have shown there are likely to be false positives for certain <br/>demographic groups, specifically Black people (particularly Black women), people of East Asian <br/>descent, women, and older adults. A promising FRT testing model does exist: DHS, through its <br/>Science and Technology Directorate, funds FRT research, testing, and evaluation at MdTF, which <br/>specializes in &ldquo;scenario testing&rdquo; of the entire FRT system as it is intended to be deployed. DHS is <br/>the only agency known to be testing FRT in this way.   Any agency using FRT should have a publicly available use policy. If agencies do use FRT, they <br/>should audit their use to ensure it complies with government policy. FRT vendors providing the <br/>federal government with solutions should provide users with ongoing training, technical support, <br/>and software updates to ensure their systems can maintain high accuracy across demographic groups <br/>in real-world deployment contexts. Furthermore, agencies should ensure their CAIOs work in close <br/>coordination with existing responsible officials and organizations within their organizations, <br/>including Civil Rights and General Counsel offices, to advise and update agency FRT guidance, <br/>implementation, and oversight. <br/>Federal grantees using FRT should provide verified results with respect to accuracy and performance <br/>across demographics from NIST&rsquo;s FRT Evaluation or similar government-validated third-party test.<br/><br/>",[],https://api.regulations.gov/v4/comments/BIS-2024-0047-0007
comment,2024-10-22T19:46:15Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0010,,,Anonymous,Public Comment 9. Individual. Annoymous,"Hi,<br/><br/>AI certainly has a perception of being one day like Skynet from Terminator 2. And my understanding is that many of these AI projects, must have some funding provided from the Department of Defense or other government entities. It would be interesting to learn for the public, as to how is machine learning for the AI, going to be used in matters of national defense. And will AI be just used as an aid or giving instructions of its own as well. I believe that the public should be also made aware of how AI is being used if they are receiving government funding. ",[],https://api.regulations.gov/v4/comments/BIS-2024-0047-0010
comment,2024-10-22T19:46:22Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0022,Alliance for Trust in AI,,,Public Comment 15. Other. Alliance for Trust in AI,Please find attached comments from the Alliance for Trust in AI. Thank you for the opportunity to provide input.,"[('ATAI BIS NPRM Significant Malicious Cyber-Enabled Activities', 'https://downloads.regulations.gov/BIS-2024-0047-0022/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0022
comment,2024-10-22T19:46:20Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0020,,,Anonymous,Public Comment 13. Individual. Anonymous (2)- Part 7 of 7,"PUBLIC COMMENT CONTINUED<br/>RIN 0694-AJ55 <br/>October 11, 2024<br/><br/>VII. BIS SHOULD CLARIFY HOW TO CALCULATE APPLICABLE THRESHOLDS.<br/><br/>BIS should also clarify how to calculate the thresholds contained within the NPRM, i.e., &ldquo;Conducting any AI model training run using more than 10^26 computational operations (e.g., integer or floating-point operations); or Acquiring, developing, or coming into possession of a computing cluster that has a set of machines transitively connected by data center networking of greater than 300 Gbit/s and having a theoretical maximum greater than 10^20 computational operations (e.g., integer or floating-point operations) per second (OP/s) for AI training, without sparsity.&rdquo;<br/><br/>In particular, BIS should define the terms &ldquo;computing cluster,&rdquo; &ldquo;transitively connected,&rdquo; and &ldquo;data center networking.&rdquo; The following definitions of these terms would be consistent with industry usage:<br/>&bull;  &ldquo;Computing cluster&rdquo; means a set of machines for which the connection between any two machines (including transitive connections) are at least 300 Gbit/s. If two machines are connected through links that are not able to operate at 300 Gbit/s, they should not be considered part of the same cluster.<br/>&bull;  &ldquo;Transitively connected&rdquo; means that two machines are connected through one or more intermediary machines, where the network bandwidth of the transitively connected machines is the bandwidth of communications between the machines based on the most direct path between the machines. For example, if machines A and B are directly connected by a 300 Gbit/s second connection, and B and C are directly connected by a 150 Gbit/s connection, then A and C are connected transitively with a 150 Gbit/s connection (as that is the maximum potential communication between the machines).<br/>&bull;  &ldquo;Data center networking&rdquo; should mean routers, switches, and other hardware components that enable connectivity needed to process data and run applications within a single data center. The term does not include modern cloud networks that incorporate virtualization to support data workloads and applications.<br/><br/>In addition, BIS should clarify the following:<br/>&bull;  What would constitute a single training run?<br/>-  If training takes place on a model, and at a later date (potentially much later) a decision is made to further fine-tune or otherwise enhance the model, is this second set of activity a new &ldquo;training run&rdquo; or a continuation of the first &ldquo;training run&rdquo;?<br/>-  Does the length of time between the two activities matter to this determination? <br/>-  Does it make a difference if the model was considered finished after the first run <br/>and put into productive use, before the later decision to further enhance it? <br/>-  Would it matter if the initial training was conducted by someone unrelated to the reporting person (e.g., an open source model) before the later fine-tuning or enhancement? <br/>&bull;  How is a training run that occurs across multiple quarters to be reported? For example, if the number of computational operations in each quarter is below the reporting threshold, but the total across all quarters is above the threshold, for which quarter (if any) would the run be reported?<br/>&bull;  What constitutes a single AI model for tallying up the resources used for training a model? For example, in cases where multiple distinct models are trained for different purposes, but in practice may be used in a coordinated way, are they to be considered a single AI model (with all of their individual training runs being consolidated for reporting as a single run)? Does it matter whether individual models are commonly used separately and not in coordination with other models?<br/>&bull;  For computing clusters:<br/>-  Are the theoretical maximum performance values based on peak performance or sustained performance?<br/>-  Is the 300 Gbit/s networking threshold a measure of per-link speed, or some other measure? If different parts of a cluster have links of different bandwidth, how does that affect the calculation?<br/>-  If two parts of a cluster are not connected transitively by links of at least 300 Gbit/s, are they considered separate clusters for purposes of the rule?<br/>-  What types of sparsity are excluded from the calculations, and how should the performance calculation take this into account?<br/>&bull;  What constitutes &ldquo;possession&rdquo; of a large-scale computing cluster, and how does shared usage of a cluster by unrelated parties affect the determination of who is in possession of it?<br/><br/>Thank you for your consideration.","[('image', 'https://downloads.regulations.gov/BIS-2024-0047-0020/attachment_1.png')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0020
comment,2024-10-22T19:46:25Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0028,Centre for the Governance of AI (GovAI),,,Public Comment 21. Center for AI Governance,See attached file(s),"[('Submitted_GovAI_Response to BIS RFC on the Establishment of Reporting Requirements for the Development of Advanced Artificial Intelligence Models and Computing Clusters', 'https://downloads.regulations.gov/BIS-2024-0047-0028/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0028
comment,2024-10-22T19:46:35Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0044,ACT | The App Association,,,Public Comment 39. Industry Association. ACT- The App Association,See attached for comments of ACT | The App Association,"[('ACT Comments re BIS Advanced AI Reporting Proposed Rule (11 Oct 2024) (w appendicies)', 'https://downloads.regulations.gov/BIS-2024-0047-0044/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0044
comment,2024-10-22T19:46:21Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0021,"Hugging Face, Inc.",,,Public Comment 14. U.S. Business. Hugging Face,The proposed rule regarding Establishment of Reporting Requirements for the Development of Advanced Artificial Intelligence Models and Computing Clusters covers important aspects of reporting; it sets clear goals of who should be required to report and excludes small actors who might not have the resources to fulfill regular reporting requirements. It further recognizes the changing nature of AI technology by ensuring that requirements and thresholds can be updated. <br/>We offer recommendations to strengthen the reporting requirements based on our experience with model documentation and work on social impact evaluations in the attached document.,"[('Hugging_Face_Comments__BIS-2024-0047__RIN 0694-AJ55', 'https://downloads.regulations.gov/BIS-2024-0047-0021/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0021
comment,2024-10-22T19:46:23Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0023,Palisade Research,,,Public Comment 16. Other. Palisade Research,Please see our comment in the attached file.,"[('BIS Comment_Palisade Research', 'https://downloads.regulations.gov/BIS-2024-0047-0023/attachment_1.pdf'), ('BIS Comment_Supplement_Wasil et al', 'https://downloads.regulations.gov/BIS-2024-0047-0023/attachment_2.pdf'), ('Supplement_Wasil et al_Semi-structured Interviews', 'https://downloads.regulations.gov/BIS-2024-0047-0023/attachment_3.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0023
comment,2024-10-22T19:46:35Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0045,ControlAI,,,Public Comment 40. Other. Control AI,See attached file(s),"[('FINAL comments on BIS-2024-0047 Establishment of Reporting Requirements', 'https://downloads.regulations.gov/BIS-2024-0047-0045/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0045
comment,2024-10-22T19:46:34Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0042,Intel Corporation,,,Public Comment 37. U.S. Business. Intel,See attached file(s),"[('Intel_comments_Reporting_Requirements_final', 'https://downloads.regulations.gov/BIS-2024-0047-0042/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0042
comment,2024-10-22T19:46:16Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0012,Institute for AI Policy and Strategy,,,Public Comment 11. Other. Institute for AI Strategy and Policy,See attached file(s),"[('IAPS Response to BIS RFC on Establishment of Reporting Requirements for Development of Advanced AI Models and Computing Clusters', 'https://downloads.regulations.gov/BIS-2024-0047-0012/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0012
comment,2024-10-22T19:46:18Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0015,,,Anonymous,Public Comment 13. Individual. Anonymous (2)- Part 2 of 7,"PUBLIC COMMENT CONTINUED<br/>RIN 0694-AJ55 <br/>October 11, 2024<br/><br/>II. THE AI MODEL TRAINING RUN REPORTING REQUIREMENT EXCEEDS THE SCOPE OF EXECUTIVE ORDER 14110 BECAUSE IT DOES NOT FOCUS ON DUAL-USE FOUNDATION MODELS AND IS TRIGGERED WHEN A COVERED U.S. PERSON MERELY CONDUCTS ANY AI MODEL TRAINING USING MORE THAN A STATED COMPUTATIONAL CAPACITY.<br/><br/>Section 4.2(a)(i) of EO 14110, &ldquo;directs the Secretary of Commerce to require companies developing, or demonstrating an intent to develop, potential dual-use foundation AI models to provide certain information to the Federal Government on an ongoing basis.&rdquo; As defined under EO 14110, a &ldquo;dual-use foundation model&rdquo; is a model that &ldquo;could be easily modified to exhibit, high levels of performance at tasks that pose a serious risk to security, national economic security, national public health or safety, or any combination of those matters.&rdquo;<br/><br/>Consistent with EO 14110, the preamble to the proposed rule provides: &ldquo;The reporting requirements proposed in this regulation are intended to apply to dual-use foundation models that meet technical conditions issued by the Department.&rdquo; BIS further states: &ldquo;the U.S. Government needs information about how many U.S. companies are developing, have plans to develop, or have the computing hardware necessary to develop dual-use foundation models, as well as information about the characteristics of dual-use foundation models under development.&rdquo;<br/><br/>Despite the focus on dual-use foundation models in EO 14110 and the preamble to the proposed rule, the AI model run reporting requirement at proposed section 702.7(a)(1)(i) are triggered when a &ldquo;covered U.S. person engages in, or plans, within six months, to engage in... conducting any AI model training run using more than 10^26 computational operations (e.g., integer or floating point operations). Notably, this trigger is not linked to dual-use foundation models. This language is much broader than the scope defined in EO 14110 because its sole focus is on computing power used to train an AI model, which is not a true indicator of whether an AI model is a dual-use foundation model that poses a significant risk to national security.<br/><br/>It is important for BIS to focus its limited resources on dual-use foundation models that pose actual national security concerns, and not unnecessarily burden industry. BIS should therefore revise proposed section 702.7(a)(1)(i), in the relevant part, to comport with the authority and intent stated at section 4.2(a)(i) of the EO 14110, as follows [recommended edits in CAPS]:<br/><br/>&ldquo;(i) Conducting any AI model training run FOR A DUAL-USE FOUNDATION MODEL using more than 10^26 computational operations (e.g., integer or floating-point operations);&rdquo;","[('image', 'https://downloads.regulations.gov/BIS-2024-0047-0015/attachment_1.png')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0015
comment,2024-10-22T19:46:34Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0043,Future of Life Institute,,,Public Comment 38. Other. Future of Life Institute,"Request for Comment attached as PDF below <br/>Organization: Future of Life Institute <br/>Point of Contact: Hamza Chaudhry, hamza@futureoflife.org","[('RfC Future of Life Institute BIS-2024-0047', 'https://downloads.regulations.gov/BIS-2024-0047-0043/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0043
comment,2024-10-22T19:46:36Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0046,Machine Intelligence Research Institute,,,Public Comment 41. Other. Machine Intelligence Research Institute,"Please see the attached file, which contains a letter with our comments. ","[('Comments on BIS reporting requirements', 'https://downloads.regulations.gov/BIS-2024-0047-0046/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0046
comment,2024-10-22T19:46:28Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0033,ITIF's Center for Data Innovation,,,Public Comment 28. Other. ITFI's Center for Data Innovation,"On behalf of the Center for Data Innovation, I am pleased to submit the attached response to the Bureau of Industry and Security&#39;s proposed rule.<br/><br/>Many thanks,<br/>Hodan Omaar<br/>Senior Policy Manager, Center for Data Innovation","[('Center for Data Innovation Comments - BIS Reporting Rule ', 'https://downloads.regulations.gov/BIS-2024-0047-0033/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0033
comment,2024-10-22T19:46:25Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0027,Hewlett Packard Enterprise (HPE),,,Public Comment 20. U.S. Business. HPE,Please find attached comments from Hewlett Packard Enterprise on the proposed rule. Please note that both public and business confidential versions are attached.,"[('P Hewlett Packard Enterprise Comments on BIS NPRM re Reporting Requirements for AI Models and Compute Clusters ', 'https://downloads.regulations.gov/BIS-2024-0047-0027/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0027
comment,2024-10-22T19:46:20Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0019,,,Anonymous,Public Comment 13. Individual. Anonymous (2)- Part 6 of 7,"PUBLIC COMMENT CONTINUED<br/>RIN 0694-AJ55 <br/>October 11, 2024<br/><br/>VI. BIS SHOULD EXPLAIN HOW IT WILL SAFEGUARD PROPRIETARY INFORMATION PROVIDED BY RESPONDENTS IN RESPONSE TO BIS REQUESTS FOR INFORMATION.<br/><br/>In the proposed rule, &ldquo;BIS recognizes that the information collected through these reporting requirements is extremely sensitive.&rdquo;  Further, the proposed rule states that &ldquo;all information submitted to the Department under this rule will be treated as confidential and afforded all the protection of section 705(d) of the DPA.&rdquo; In addition, information provided in response to BIS questions is considered exempt from the Freedom of Information Act, 5 U.S.C. &sect; 552(b), and protected from disclosure under and 18 U.S.C. &sect; 1905.<br/><br/>Given the U.S. Government&rsquo;s obligations to safeguard information provided by industry in response to BIS requests, the highly competitive nature of AI development, the highly confidential and proprietary nature of the information that will be requested by BIS, the history of U.S. Government data breaches, and the irreparable harm that would be caused by leaks and/or by BIS sharing confidential and proprietary industry information, BIS should clarify how sensitive information to be provided by respondents will be safeguarded from competitors and other members of the public.<br/><br/>More specifically, BIS should answer the following questions in any final rule:<br/>1.  How BIS plans to have respondents transmit responses to BIS questions? <br/>2.  What security measures BIS will take to ensure that the information in industry member reports will be adequately secured while in transit to the government, on BIS&rsquo;s survey system, and at rest on government servers? <br/>3.  Under what situations and conditions BIS may share information in industry member reports with other government agencies, members of Congress, and any other third-party recipients? <br/>4.  Are there any circumstances in which BIS would share information in industry member reports with private third parties, to include government contractors?<br/>5.  How will BIS transmit information in industry member reports to third-party recipients? <br/>6.  What security measures will BIS require of third-party recipients to ensure that the recipients will adequately secure information in industry member reports while in transit and at rest?<br/>7.  What restrictions will BIS impose on third party sharing of information in industry member reports? <br/>8.  How will BIS verify whether third-party recipients are complying with restrictions on sharing information in industry member reports?","[('image', 'https://downloads.regulations.gov/BIS-2024-0047-0019/attachment_1.png')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0019
comment,2024-10-22T19:46:37Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0047,Encode Justice,,,Public Comment 23. Other. Encode Justice,See attached file(s),"[('Encode Justice - Bureau of Industry and Security (BIS) Comment - 15 CFR Part 702', 'https://downloads.regulations.gov/BIS-2024-0047-0047/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0047
comment,2024-10-22T19:46:24Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0025,Convergence Analysis,,,Public Comment 18. Other. Convergence Analysis," Please refer to our uploaded files: <br/><br/>- Our Official Comment:<br/>&quot;Convergence Analysis Comment on Establishment of Reporting Requirements for the Development of Advanced Artificial Intelligence Models and Computing Clusters.pdf&quot; <br/><br/>- Our recently published report on frontier model reporting requirements, referred to in our comment: <br/>&quot;AI Model Registries - A Foundational Tool for AI Governance.pdf&quot;","[('Convergence Analysis Comment on Establishment of Reporting Requirements for the Development of Advanced Artificial Intelligence Models and Computing Clusters', 'https://downloads.regulations.gov/BIS-2024-0047-0025/attachment_1.pdf'), ('AI Model Registries - A Foundational Tool for AI Governance', 'https://downloads.regulations.gov/BIS-2024-0047-0025/attachment_2.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0025
comment,2024-10-22T19:46:27Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0031,Information Technology Industry Council (ITI),,,Public Comment 26. Industry Association. Information Technology Industry Council,See attached file(s),"[('ITI Feedback on BIS AI Reporting Final', 'https://downloads.regulations.gov/BIS-2024-0047-0031/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0031
comment,2024-10-22T19:46:28Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0032,Recording Industry Association of America (RIAA),,,Public Comment 27. Industry Association. Recording Industry Association of America,See attached file(s),"[('RIAA Comments on BIS NPRM', 'https://downloads.regulations.gov/BIS-2024-0047-0032/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0032
comment,2024-10-22T19:46:33Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0041,OpenAI,,,Public Comment 36. U.S. Business. OpenAI,See attached file(s),"[('OpenAI Comment on BIS Proposed Rule (No. 240905-0242)', 'https://downloads.regulations.gov/BIS-2024-0047-0041/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0041
comment,2024-10-22T19:46:37Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0048,METR - Model Evaluation Threat Research,,,Public Comment 43. Other. METR- Model Evaluation Threat Research,See attached file(s),"[('METR_Comment_10-11-24', 'https://downloads.regulations.gov/BIS-2024-0047-0048/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0048
comment,2024-10-22T19:46:31Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0038,The Electronic Privacy Information Center (EPIC),,,Public Comment 33. Other. The Electronic Privacy Information Center,See attached file(s),"[('DOC BIS Proposed AI Rule - EPIC Comments', 'https://downloads.regulations.gov/BIS-2024-0047-0038/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0038
comment,2024-10-22T19:46:17Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0014,,,Anonymous,Public Comment 13. Individual. Anonymous (2)- Part 1 of 7,"PUBLIC COMMENT<br/>RIN 0694-AJ55 <br/>October 11, 2024<br/><br/>The following comments and recommended revisions are provided below in response to the U.S. Department of the Commerce, Bureau or Industry and Security (BIS) proposed rule on &ldquo;Establishment of Reporting Requirements for the Development of Advanced Artificial Intelligence Models and Computing Clusters&rdquo; published on September 11, 2024, under 89 Fed. Reg. 73612.<br/><br/>This comment is being submitted in seven parts/sections due to the character limit on the Regulations.gov comment submission form.<br/><br/>I. BIS SHOULD PERFORM A COSTS-BENEFITS ANALYSIS OF THE PROPOSED REPORTING REQUIREMENTS<br/> <br/>As a preliminary matter, BIS should perform a sufficient costs-benefits analysis of the likely impacts of the proposed reporting requirements on U.S. technological leadership in AI.<br/><br/>Relevant to this analysis, a key conclusion from the agency&rsquo;s 1994 AI industrial base assessment found:<br/><br/>&ldquo;The United States leading position in AI is eroding as the government and companies in Japan, as well as in Western Europe, working together, have gained ground. In select areas of AI, Japan and Western Europe now surpass the U.S.&rdquo;<br/><br/>See Critical Technology Assessment of the Artificial Intelligence Sector (August 1994), available at www.bis.doc.gov/index.php/documents/technology-evaluation/33-critical-technology-assessment-of-u-s-artificial-intelligence-1994/file<br/><br/>In the proposed rule, BIS states that it needs ongoing quarterly reports for information &ldquo;that will allow the U.S. Government to determine whether action is necessary to stimulate development of dual-use foundation models or to support the development of specific types of models.&rdquo; However, the government is no longer a significant source of funding or other incentives for AI research and development, and it is unlikely to have sufficient resources to do so in an impactful way. This is because, since the agency&rsquo;s 1994 AI assessment, a fundamental shift in the marketplace has reshaped the AI research and development landscape. Specifically, compared to 1994, today&rsquo;s AI research and development is:<br/>&bull; reliant on funding by the commercial sector, which contributes billions upon billions of dollars towards these efforts;<br/>&bull; the focus of fierce commercial competition in the United States and abroad;<br/>&bull; in advanced stages of development by non-U.S. allied countries;<br/>&bull; significantly supported by non-U.S. engineers; and<br/>&bull; increasingly used in everything from online search tools, e-commerce, travel, and a wide array of other civilian applications.<br/><br/>Imposing ongoing quarterly reporting requirements, expanding export controls, imposing limits on academic funding by non-U.S. companies, and other limitations on AI research and development in the United States will incentivize companies to move research and development abroad. Further, based on lessons learned from export controls on the U.S. commercial satellite, semiconductor, and other industries, increased regulatory requirements are likely to lead the international community to exclude U.S. industry from the global marketplace of ideas necessary to maintaining U.S. technological leadership. BIS should therefore undertake a more careful consideration of the costs and benefits than is reflected in the proposed rule.","[('image', 'https://downloads.regulations.gov/BIS-2024-0047-0014/attachment_1.png')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0014
comment,2024-10-22T19:46:15Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0011,Hacking Policy Council,,,Public Comment 10. Other. Hacking Policy Council,See attached file(s),"[('Hacking Policy Council - Comments to BIS re reporting requirements for advanced AI - 20241010', 'https://downloads.regulations.gov/BIS-2024-0047-0011/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0011
comment,2024-10-22T19:46:29Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0034,Anthropic PBC,,,Public Comment 29. U.S. Business. Anthropic,See attached file(s),"[('Anthropic Comment on BIS-2024-0047', 'https://downloads.regulations.gov/BIS-2024-0047-0034/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0034
comment,2024-10-22T19:46:23Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0024,U.S. Chamber of Commerce,,,Public Comment 17. Industry Association. U.S. Chamber of Commerce,See attached file(s),"[('CTEC_Comments_AI ModelsComputing_Commerce_Final', 'https://downloads.regulations.gov/BIS-2024-0047-0024/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0024
comment,2024-10-22T19:46:19Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0017,,,Anonymous,Public Comment 13. Individual. Anonymous (2)- Part 4 of 7,"PUBLIC COMMENT CONTINUED<br/>RIN 0694-AJ55 <br/>October 11, 2024<br/><br/>IV. THE COMPUTING CLUSTER REPORTING REQUIREMENT SHOULD ONLY APPLY WHEN A COMPUTING CLUSTER ACTUALLY EXCEEDS A STATED THRESHOLD AND NOT MERELY WHEN THERE IS A POTENTIAL TO EXCEED A THRESHOLD.<br/><br/>Section 4.2(a)(ii) of EO 14110 mandates that &ldquo;companies, individuals, or other organizations or entities that acquire, develop, or possess a potential large-scale computing cluster must report any such acquisition, development, or possession, including the existence and location of these clusters and the amount of total computing power available in each cluster.&rdquo;<br/><br/>The computing cluster reporting requirement should not apply when there is merely a potential to exceed a certain performance threshold because performance thresholds are most often not determined at the time of acquiring hardware or standing up a computing cluster (pre-build, or even semi build). To the contrary, U.S. covered persons generally do not know whether or not hardware being installed would meet a threshold until after a cluster is built, and all the hardware is up and running at a datacenter.  While they may have estimates or some plans regarding how the computing cluster will be used, they often get updated and changed as it currently takes anywhere between 18-24 months for a new data center to come online.<br/><br/>As proposed, section 702.7(a)(1)(ii) requires quarterly reporting where a covered U.S. person &ldquo;engages in, or plans, within six months, to engage in&rdquo; activities that involve &ldquo;[a]cquiring, developing, or coming into possession of a computing cluster that&rdquo; exceeds stated thresholds. Nevertheless, the inconsistency between the language in EO 14110 (which refers to a &ldquo;potential large-scale computing cluster&rdquo;) and proposed section 702.7(a)(1)(ii) could cause over-reporting by companies with resources that could potentially be networked to exceed the stated performance parameters.<br/><br/>BIS should therefore revise section 702.7(a)(1)(ii) to clarify that the computing cluster reporting requirement only applies when a covered person has &ldquo;knowledge&rdquo; as defined in EAR section 772.1 that a computing cluster actually exceeds stated thresholds, and not when there is merely the potential to exceed a threshold.<br/><br/>More specifically, BIS should revise proposed section 702.7(a)(1)(ii) as follows [recommended edits in CAPS]:<br/><br/>(ii) Acquiring, developing, or coming into possession of a computing cluster that THE COVERED PERSON KNOWS has a set of machines transitively connected by data center networking of greater than 300 Gbit/s and having a theoretical maximum greater than 10^20 computational operations ( e.g., integer or floating-point operations) per second (OP/s) for AI training, without sparsity.","[('image', 'https://downloads.regulations.gov/BIS-2024-0047-0017/attachment_1.png')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0017
comment,2024-10-22T19:46:31Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0039,The Abundance Institute,,,Public Comment 34. Other. The Abundance Institute,"See the attached document for the comments of Neil Chilson, Head of AI Policy at the Abundance Institute, arguing that because Section 4.2 of the EO exceeds DPA authority, the proposed rule is unauthorized. It is also contrary to existing BIS rules. BIS should not adopt it. <br/><br/>However, if BIS does pursue reporting requirements it should do so by periodically issuing one-time surveys through the normal survey process, to parties identified by BIS. At a minimum, BIS must offer a full-fledged legal justification for how the proposed rule complies with the DPA and the existing BIS rules, and further detail how the rule complies with the PRA and RFA.<br/>","[('Comments of the Abundance Institute - BIS Reporting Requirements (FINAL)', 'https://downloads.regulations.gov/BIS-2024-0047-0039/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0039
comment,2024-10-22T19:46:16Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0013,Group 42 Holding Ltd,,,Public Comment 12. Foreign Business. G42,Group 42 Holding Ltd respectfully submits the attached comment letter regarding BIS-2024-0047-0001.<br/><br/>,"[('BIS-2024-0047 Comment Letter _G42', 'https://downloads.regulations.gov/BIS-2024-0047-0013/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0013
comment,2024-10-22T19:46:38Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0049,Center for AI Risk Management & Alignment,,,Public Comment 44. Other. Center for AI Risk Management & Alignment,"Establishment of Reporting Requirements for the Development of Advanced Artificial Intelligence Models and Computing Clusters:<br/><br/>Response from the Center for AI Risk Management &amp; Alignment (CARMA) to the Bureau of Industry and Security (BIS) Request for Public Comment<br/><br/>Center for AI Risk Management &amp; Alignment (CARMA)<br/><br/>October 11, 2024<br/><br/>The Center for AI Risk Management &amp; Alignment (CARMA) appreciates the opportunity to provide feedback on the Bureau of Industry and Security (BIS) rule for the Establishment of Reporting Requirements for the Development of Advanced Artificial Intelligence Models and Computing Clusters, pursuant to the Executive Order on Safe, Secure and Trustworthy AI (E.O. 14110). This rule is a promising step toward ensuring transparency and accountability from AI companies working on the most advanced &ldquo;dual use foundation models&rdquo; while securing the safety and competitiveness of the U.S. defense industrial base. <br/><br/>Our response to this Request for Comment aims to support BIS in aligning the reporting requirements with the intended goals of the Executive Order, ensuring robust protection from advanced AI risks. We emphasize the importance of adaptive, regulatory frameworks, robust risk assessments, and the need for secure reporting channels to enable<span style='padding-left: 30px'></span>whistleblower protection. These recommendations are designed to support BIS in mitigating risks while ensuring societal resilience.<br/><br/>CARMA is a technical governance thinktank focused on developing a more accurate mapping of risks from advanced AI systems and characterizing novel policy approaches to ensure societal safety and security.<br/><br/>Overview<br/><br/>AI has quickly become an integral part of large segments of the economy and industry, including those that are crucial to U.S. national defense. This includes manufacturers of military equipment that use AI models &ldquo;to enhance the maneuverability, accuracy, and efficiency of equipment,&rdquo; tools central to intelligence collection, and secondary components that extend the capabilities of the U.S. defense industrial base (BIS-2024-0047). Whether this information is actionable for national defense depends largely on the accuracy, robustness, and reliability of the reporting from model developers. <br/><br/>In support of E.O. 14110, which requires reporting from companies planning to develop dual use foundation models, and BIS&rsquo;s authorities under the Defense Production Act (DPA), this comment seeks to ensure that the Department of Commerce has the greatest possible visibility into potential risks or indicators of unexpected behavior from developers of advanced general-purpose AI systems. Our six key recommendations include:<br/><br/>Significant Activity Reporting (SAR): Amend reporting requirements to include unscheduled updates on significant events like technological breakthroughs or unexpected failures, ensuring timely notifications of emergent capabilities and potential risks outside the quarterly schedule.<br/><br/>Secure Channel for Anonymous Reporting: Establish a secure, anonymous channel to report concerns over unsafe practices, vulnerabilities, or emergent capabilities, allowing critical information to be shared without fear of retribution and ensuring timely updates on potential security threats.<br/><br/>Comprehensive Risk Assessment and Independent Validation: Require companies to conduct thorough pre-deployment risk assessments and provide red-teaming data to BIS for independent validation and verification, allowing an additional layer of security.<br/><br/>Monitoring Large Compute Clusters: Establish a registration and licensing system for large-scale compute clusters, providing BIS with the means to monitor the development of powerful AI systems while developing alternative, adaptive approaches to monitor novel AI paradigms.<br/><br/>On-Chip Compute Governance: Implement on-chip governance mechanisms, such as delay-based geolocation, to verify chip locations, enforce export controls, and monitor the lifecycle of model development, ensuring compliance with national security regulations.<br/><br/>Metrics to Track Evolving AI Paradigms: Convene expert panel to devise tractable metrics beyond compute-based thresholds to account for evolving AI paradigms like decentralized and inference-based compute. <br/><br/>The majority of this comment focuses on recommendations under the mandatory notifications section (1. Quarterly Notification Schedule), as this is the most crucial short-term path to obtaining timely threat information. <br/><br/>See the attachment for the more detailed response. <br/>","[('RFC Center for AI Risk Management and Alignment - BIS-2024-0047', 'https://downloads.regulations.gov/BIS-2024-0047-0049/attachment_1.pdf'), ('RFC Center for AI Risk Management and Alignment BIS-2024-0047', 'https://downloads.regulations.gov/BIS-2024-0047-0049/attachment_2.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0049
comment,2024-10-22T19:46:29Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0035,AE Studio,,,Public Comment 30. U.S. Business. AE Studio,"We are AE Studio, a bootstrapped 150+ person data science, dev, and design consultancy. We reinvest profits into impact-focused foundational research, like neurotechnology and AI alignment, with the mission to increase human agency. <br/><br/>Our company works with frontier models across a wide array of clients within and beyond the tech sector, from the largest corporations to startups outsourcing their first technical projects to us, across a wide range of applications. To survive in our industry, we excel in our client work, with the best technical talent keeping up to date with the cutting edge of AI capabilities.<br/><br/>We are thankful to the Bureau of Industry and Security for their work concerning the future of AI. We believe AI has a highly uncertain future, and in some possible scenarios, perhaps inevitably, advanced AI models will be immensely capable and essential for national security and for the flourishing of our economy. <br/><br/>But the possible risks need to be managed. We should not entirely trust our future, the next nuclear technology, to the private sector, yet we should not also preemptively stifle essential innovation. We must defensively accelerate, and America must win the AI race, should there be one.<br/><br/>Monitoring the state of the art in the AI labs of America is the only way the US will be able to ensure we both: lead on the technology, and mitigate risks from the technology. Doing so with minimal friction such that we perfectly balance safety with winning, is our task.<br/><br/>Overview<br/>Enhancing Reporting Requirements for Dual-Use Foundation Model Developers<br/><br/>We present several proposals to strengthen the effectiveness and reliability of reporting requirements for entities developing dual-use foundation models. Our focus is on recommendations that the Bureau of Industry and Security (BIS) can implement within its current authority, prioritizing ideas that require minimal additional resources.<br/><br/>Key Recommendations<br/><br/>1. Establish a Protected/Anonymous Reporting Channel: Create a secure mechanism for employees of entities developing dual-use foundation models to report concerns. This channel (ai_reporting@bis.doc.gov) would allow staff to disclose:<br/>   a) Potential inaccuracies or misleading information in company reports to BIS<br/>   b) Safety and reliability issues related to dual-use foundation models<br/>   c) Activities or risks that may impact U.S. national security<br/><br/>   Ideally, this platform should be both protected (prohibiting retaliation) and anonymous. If protection is unfeasible, an anonymous system would still be valuable. Entities should confirm in their reports that employees are aware of this mechanism and that company policies do not hinder its use.<br/><br/>2. Implement Regular Employee Interviews: Conduct quarterly interviews with staff from entities producing dual-use foundation models. BIS would select interviewees from various teams to gather diverse insights. These conversations would cover model capabilities, safety and security concerns, and predictions about AI advancements that could pose new safety and security risks.<br/><br/>3. Require Capability Forecasts: In addition to red-team testing reports, companies should provide their best estimates of when they or others might develop dual-use foundation models with specific security-relevant capabilities. This would assist the U.S. industrial base and defense sector in making informed predictions about future AI advancements and their defense implications.<br/><br/>4. Mandate a Summary Form for Non-Experts: Alongside detailed reports, require entities to submit a concise Summary Form accessible to non-technical audiences. This form would highlight the most critical defense-relevant information in a clear, easily digestible format.<br/><br/>5. Modify Notification Conditions: Require entities to inform BIS of significant capability improvements that present immediate security risks within 5 days of discovery. This ensures BIS is promptly notified of crucial advancements between quarterly reports.<br/><br/>We suggest applying these recommendations to all entities developing dual-use foundation models. However, if this proves impractical, focusing on the top 10 entities would still yield valuable information for U.S. industrial and national defense interests.<br/>","[('AE Studio BIS RFC', 'https://downloads.regulations.gov/BIS-2024-0047-0035/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0035
comment,2024-10-22T19:46:13Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0006,Center for Progress,,Calzada,Public Comment 5. Other. Center for Progress.,See attached file(s),"[('Bureau of Industry and Security (BIS) comment (Dual use models) ', 'https://downloads.regulations.gov/BIS-2024-0047-0006/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0006
comment,2024-10-22T19:46:30Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0037,CTIA – The Wireless Association,,,Public Comment 32. Industry Association. CTIA,Please see the attached PDF,"[('CTIA BIS comment letter 10.11.24 vF', 'https://downloads.regulations.gov/BIS-2024-0047-0037/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0037
comment,2024-10-22T19:46:26Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0029,TechNet,,,Public Comment 24. Industry Association. Tecnet,See attached file(s),"[('FINAL TechNet Comment to BIS re Foundation Model Reporting', 'https://downloads.regulations.gov/BIS-2024-0047-0029/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0029
comment,2024-10-22T19:46:24Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0026,AdvaMed,,,Public Comment 19. U.S. Business. AdvaMed Imaging,See attached file(s),"[('AdvaMed Imaging - AIC - ISB Proposed Rule - 20241011 - FINAL', 'https://downloads.regulations.gov/BIS-2024-0047-0026/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0026
comment,2024-10-22T19:46:27Z,BIS-2024-0047,BIS-2024-0047-0001,BIS-2024-0047-0030,Computer & Communications Industry Association,,,Public Comment 25. Industry Association. Computer and Communications Industry Association,See attached file.,"[('2024-10-11 CCIA Comments to BIS on Reporting Requirements for Advanced AI Models and Computing Clusters', 'https://downloads.regulations.gov/BIS-2024-0047-0030/attachment_1.pdf')]",https://api.regulations.gov/v4/comments/BIS-2024-0047-0030
